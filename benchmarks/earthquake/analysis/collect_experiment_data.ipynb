{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7960ed21",
   "metadata": {},
   "source": [
    "# MLCommons Earthquake GPU Data Collection\n",
    "- Creates Pickle file with data for all available runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13237d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import pickle\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7759ae0",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- Make paths smarter ex. if 'card_name_' in dir save there, else higher level\n",
    "- Add NNSE stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121576d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get time\n",
    "now = datetime.datetime.now()\n",
    "print(now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304efebc",
   "metadata": {},
   "source": [
    "### Data Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab1e45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_gpu_log(path):\n",
    "    \"\"\" Format the gpu data log into dataframe.\n",
    "\n",
    "    Args:\n",
    "        path: file path for the gpu log.\n",
    "    Returns:\n",
    "        dataframe with gpu data.\n",
    "    \"\"\"\n",
    "    # read in data\n",
    "    gpu_df = pd.read_csv(path, skiprows=1,header=None,low_memory=False)\n",
    "    \n",
    "    # get headers\n",
    "    header = gpu_df.loc[0]\n",
    "    header = header.str[2:].str.strip()\n",
    "    gpu_df = gpu_df.drop(index = [0]).reset_index(drop=True)\n",
    "    gpu_df= gpu_df.set_axis(header,axis=1,inplace=False)\n",
    "    \n",
    "    # set types\n",
    "    int_col = list(gpu_df.columns[1:-1])\n",
    "    gpu_df[int_col] = gpu_df[int_col].astype('int')\n",
    "    float_col = list(gpu_df.columns[-1:])\n",
    "    gpu_df[float_col] = gpu_df[float_col].astype('float')\n",
    "    time_col = list(gpu_df.columns[:1])[0]\n",
    "\n",
    "    gpu_df = gpu_df.groupby('time').mean().reset_index()\n",
    "    \n",
    "    return gpu_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3b9c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timer_data(err_path):\n",
    "    \"\"\" Collect timer data from run output and create dataframe and csv.\n",
    "\n",
    "    Args:\n",
    "        path: file path for the run log.\n",
    "    Returns:\n",
    "        dataframe with timer data.\n",
    "    \"\"\"   \n",
    "    def index_containing_substring(the_list, substring, _not=False):\n",
    "        index = []\n",
    "        for i, s in enumerate(the_list):\n",
    "            if not _not:\n",
    "                if substring in s:\n",
    "                    index.append(i)\n",
    "            else:\n",
    "                if substring not in s:\n",
    "                    index.append(i)\n",
    "        if _not:\n",
    "            return index\n",
    "        elif substring == '# csv,RUN_STOP' or substring == '# csv,label3':\n",
    "            if len(index) < 2:\n",
    "                return -1\n",
    "            return index[-2] + 1\n",
    "        elif not index is None:\n",
    "            return index[-1]\n",
    "        return -1    \n",
    "\n",
    "    directory = err_path.rsplit(\"/\",1)[0]\n",
    "    output_path = os.path.join(directory,'timer.csv')\n",
    "    \n",
    "    # read in data\n",
    "    with open(err_path) as f:\n",
    "        content = f.readlines()\n",
    "    \n",
    "    success = any([True if 'Execution Complete' in x else False for x in content])\n",
    "    if not success:\n",
    "        print(f'Incomplete Run: {directory}')\n",
    "        return None\n",
    "    \n",
    "    timerUpdate = any([True if 'RUN_STOP' in x else False for x in content])\n",
    "    if timerUpdate:\n",
    "        # get timer content\n",
    "        start = index_containing_substring(content, '# csv,timer,status,time,sum,start,tag,msg,uname.node,user,uname.system,platform.version')\n",
    "        stop = index_containing_substring(content, '# csv,RUN_STOP')\n",
    "        if stop == -1:\n",
    "            print(f'Incomplete Run: {directory}')\n",
    "            return None\n",
    "        content = content[start:stop]\n",
    "        neg = index_containing_substring(content, '# csv', _not=True)\n",
    "\n",
    "        # fix for dictionary in csv\n",
    "        fixed = ''.join(content[min(neg):max(neg)+1]).strip().replace('\\n','').replace('\\s+','').replace('\\t+','')\n",
    "        for x in range(min(neg),max(neg)+1):\n",
    "            content.pop(min(neg))\n",
    "    else:\n",
    "        # get timer content\n",
    "        start = index_containing_substring(content, '# csv,timer,status,time,sum,start,tag,msg,uname.node,user,uname.system,platform.version')\n",
    "        stop = index_containing_substring(content, '# csv,label3')\n",
    "        if stop == -1:\n",
    "            print(f'Incomplete Run: {directory}')\n",
    "            return None\n",
    "        content = content[start:stop]\n",
    "                      \n",
    "    # formatting\n",
    "    times = []\n",
    "    for x in content:\n",
    "        times.append(x.strip('\\n').replace('# csv,',''))\n",
    "    if timerUpdate:\n",
    "        times[min(neg)-1] = times[min(neg)-1]+fixed\n",
    "    data = []\n",
    "    for x in times:\n",
    "        x = re.sub(\"\\{[^}]*\\}\", lambda x:x.group(0).replace(',',';'), x)\n",
    "        data.append(x)\n",
    "    \n",
    "    # save off data\n",
    "    df = pd.DataFrame(data)[0].str.split(',', expand=True)\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df[1:]\n",
    "\n",
    "    # convert to datetime\n",
    "    df['start'] = pd.to_datetime(df['start'], format='%Y-%m-%d %H:%M:%S')\n",
    "    df = df[df['status'] != 'failed']\n",
    "    \n",
    "    # get end time\n",
    "    for i, row in df.iterrows():\n",
    "        df.loc[i,'end'] = row['start'] + datetime.timedelta(seconds=float(row.time))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f60d828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_power_data(data_dict):\n",
    "    \"\"\" Convert gpu dataframe into data for plots.\n",
    "    Args:\n",
    "        data_dict: dictionary of run data. \n",
    "    Returns:\n",
    "        dataframe with power data.\n",
    "    \"\"\"   \n",
    "    # setup\n",
    "    data = {}\n",
    "    rename = {\n",
    "        '# time': 'time',\n",
    "        'id': 'id',\n",
    "        'gpu_util %': 'gpu_util',\n",
    "        'memory_util %': 'memory_util',\n",
    "        'encoder_util %': 'encoder_util',\n",
    "        'decoder_util %': 'decoder_util',\n",
    "        'gpu_temp C': 'gpu_temp',\n",
    "        'power_draw W': 'power_draw'\n",
    "    }\n",
    "    \n",
    "    # collect run info\n",
    "    data['gpu'] = data_dict['run_info']['gpu']\n",
    "    data['numGpus'] = data_dict['run_info']['numGpus']\n",
    "    data['numCpus'] = data_dict['run_info']['numCpus']\n",
    "    data['mem'] = data_dict['run_info']['mem']\n",
    "    data['epochs'] = data_dict['run_info']['epochs']\n",
    "    \n",
    "    # build power data total notebook\n",
    "    gpu_df = data_dict['gpu_df'].rename(columns=rename)\n",
    "    grouped = gpu_df.groupby(['time']).mean()['power_draw'].reset_index()       \n",
    "    data['kWh_total'] = sum(grouped['power_draw'])*(1/3600)*(1/1000)\n",
    "    data = pd.DataFrame([data], columns=data.keys())\n",
    "    \n",
    "    # build power data model fit\n",
    "    timer_df = data_dict['timer_df']\n",
    "    delta = min(timer_df['start']) - min(grouped['time']).round('1h')\n",
    "    fit_event = timer_df.loc[timer_df['timer'] == 'RunTFTCustomVersion train']\n",
    "    fit_start = fit_event['start'] - delta\n",
    "    fit_end = fit_event['end'] - delta\n",
    "    fit_grouped = grouped[(grouped['time'] >= fit_start.values[0]) & (grouped['time'] <= fit_end.values[0])]\n",
    "    data['kWh_fit'] = sum(fit_grouped['power_draw'])*(1/3600)*(1/1000)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee67c81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_NNSE_data(err_path):\n",
    "    with open(err_path) as f:\n",
    "        lines = f.readlines()\n",
    "    NNSE_lines = []\n",
    "    for line in lines:\n",
    "        if 'NNSE \\n' in line:\n",
    "            line = line.replace(\"\\n\", \"\").strip()\n",
    "            NNSE_lines.append(line)\n",
    "            num = 5\n",
    "        elif num != 0:\n",
    "            NNSE_clean = NNSE.replace(\"\\n\", \"\").strip()\n",
    "            lis.append(NNSE_clean)\n",
    "            num -= 1\n",
    "            if num == 0:\n",
    "                full_lis.append(lis)\n",
    "                lis = []\n",
    "    import pdb; pdb.set_trace()\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234fa944",
   "metadata": {},
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77881e21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# find run directories\n",
    "cwd = os.getcwd()\n",
    "directories = [os.path.join(cwd,x) for x in os.listdir(cwd) if os.path.isdir(x)]\n",
    "\n",
    "data_dict = {}\n",
    "for system in directories:\n",
    "    filesystems = [os.path.join(system,x) for x in os.listdir(system) if os.path.isdir(os.path.join(system,x))]\n",
    "    for filesystem in filesystems:\n",
    "        dates = [os.path.join(filesystem,x) for x in os.listdir(filesystem) if os.path.isdir(os.path.join(filesystem,x))]\n",
    "        for date in dates:\n",
    "            experiments = [os.path.join(date,x) for x in os.listdir(date) if os.path.isdir(os.path.join(date,x))]\n",
    "            for experiment in experiments:\n",
    "                if 'card_name' in experiment:\n",
    "                    print(experiment)\n",
    "                    if '_output' in os.listdir(experiment):\n",
    "                        log_path = glob.glob(os.path.join(experiment,'*.err'))\n",
    "                        if not log_path:\n",
    "                            print(f\"Incomplete Run: {experiment}\")\n",
    "                            continue\n",
    "                        timer_df = get_timer_data(log_path[0])\n",
    "                        if timer_df is None:\n",
    "                            print(f\"Incomplete Run: {experiment}\")\n",
    "                            continue\n",
    "                        experiment_path = experiment\n",
    "                        experiment = experiment.split('/')[-1]\n",
    "                        system = system.split('/')[-1].replace('-','_')\n",
    "                        filesystem = filesystem.split('/')[-1]\n",
    "                        date = date.split('/')[-1]\n",
    "                        #nsse_df = get_NNSE_data(log_path)\n",
    "                        experiment_name = f\"{experiment}.{system}.{filesystem}.{date}\"\n",
    "                        gpu_log = os.path.join(experiment_path,'_output/Outputs/gpu0.log')\n",
    "                        if os.path.exists(os.path.join(experiment_path,'_output/images/Outputs/gpu0.log')):\n",
    "                            gpu_log = os.path.join(experiment_path,'_output/images/Outputs/gpu0.log')\n",
    "                        elif os.path.exists(os.path.join(experiment_path,'_output/Outputs/gpu0.log')):\n",
    "                            gpu_log = os.path.join(experiment_path,'_output/Outputs/gpu0.log')\n",
    "                        else:\n",
    "                            print(f'Check path for GPU log for {experiment_path}')\n",
    "                            continue         \n",
    "                        gpu_df = format_gpu_log(gpu_log)\n",
    "                        if gpu_df is None:\n",
    "                            continue\n",
    "                        data_dict[experiment_name] = {}\n",
    "                        \n",
    "                        if experiment.split('.')[-1].split('_')[2] == '1':\n",
    "                            gpu = 'a100'\n",
    "                        else:\n",
    "                            gpu = experiment.split('.')[-1].split('_')[2]\n",
    "                        \n",
    "                        # add run info to dictionary\n",
    "                        data_dict[experiment_name]['run_info'] = {\n",
    "                            'system': system,\n",
    "                            'filesystem': filesystem,\n",
    "                            'date': date,\n",
    "                            'gpu': gpu,\n",
    "                            'numGpus': experiment.split('.')[-1].split('_')[5],\n",
    "                            'numCpus': experiment.split('.')[-1].split('_')[8],\n",
    "                            'mem': experiment.split('.')[-1].split('_')[10],\n",
    "                            'epochs': experiment.split('.')[-1].split('_')[-1],\n",
    "                            'path': experiment_path\n",
    "                        }\n",
    "\n",
    "                        # add DataFrames to dictionary\n",
    "                        data_dict[experiment_name]['gpu_df'] = gpu_df\n",
    "                        data_dict[experiment_name]['timer_df'] = timer_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50bbbb4",
   "metadata": {},
   "source": [
    "### Get archived data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09d29b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive = os.path.join(cwd,'rtx3090','archive')\n",
    "if os.path.exists(archive):\n",
    "    mar2022_df = pd.read_csv(os.path.join(archive,'mar2022_data.csv'))\n",
    "    for i, row in mar2022_df.iterrows():\n",
    "        row = row.rename({'Unnamed: 0':'experiment'})\n",
    "        row['experiment'] = f\"mar2022_{row['experiment']}\"\n",
    "        experiment = row['experiment']\n",
    "        if 'colab' not in row['experiment']:\n",
    "            system = 'rivanna'\n",
    "        else:\n",
    "            system = 'colab'\n",
    "        date, gpu, filesystem, epochs = row['experiment'].split('_')\n",
    "        experiment_name = f\"{experiment}.{system}.{filesystem}.{date}\"\n",
    "        # run info\n",
    "        data_dict[experiment_name] = {}\n",
    "        data_dict[experiment_name]['run_info'] = {\n",
    "            'system': system,\n",
    "            'filesystem': filesystem,\n",
    "            'date': date,\n",
    "            'gpu': experiment_name.split('_')[1].lower(),\n",
    "            'numGpus': 1,\n",
    "            'numCpus': 1,\n",
    "            'mem': np.nan,\n",
    "            'epochs': epochs,\n",
    "            'path': np.nan\n",
    "        }\n",
    "        # timer df\n",
    "        if not gpu == 'V100':\n",
    "            timer_df = row.drop(['experiment','__RunTFTCustomVersion bestfit']).to_frame().reset_index()\n",
    "        else:\n",
    "            timer_series = row.drop('experiment')\n",
    "            bestfit = row['__RunTFTCustomVersion bestfit']\n",
    "            timer_series = row.drop('__RunTFTCustomVersion bestfit')\n",
    "            row['RunTFTCustomVersion bestfit'] = bestfit\n",
    "            timer_df = row.to_frame().reset_index()\n",
    "        timer_df.columns = ['timer', 'time']\n",
    "\n",
    "        data_dict[experiment_name]['timer_df'] = timer_df\n",
    "\n",
    "        # gpu df\n",
    "        data_dict[experiment_name]['gpu_df'] = None\n",
    "    \n",
    "    epoch2_table = pd.read_csv(os.path.join(archive,'epoch2_table.csv')).drop('Unnamed: 0', axis=1).rename(columns={'Unnamed: 0.1': 'experiment'})\n",
    "    for i, row in epoch2_table.iterrows():\n",
    "        gpu = row['experiment'].split('(')[0].lower()\n",
    "        system = row['experiment'].split('(')[1][0]\n",
    "        if system == 'r':\n",
    "            system = 'rivanna'\n",
    "            filesystem = 'rivanna'\n",
    "        elif system == 'R':\n",
    "            system = 'personal_pc_r'\n",
    "            filesystem = 'personal_pc_r'\n",
    "        elif system == 'G':\n",
    "            system = 'personal_pc_g'\n",
    "            filesystem = 'personal_pc_g'\n",
    "        elif system == 'L':\n",
    "            system = 'rivanna'\n",
    "            filesystem = 'localscratch'\n",
    "        elif system == 'c':\n",
    "            system = 'colab'\n",
    "            filesystem = 'colab'\n",
    "        experiment_name = f'mar2022_epoch2_{gpu}_{system}_{filesystem}.{system}.{filesystem}.mar2022'\n",
    "\n",
    "        # run info\n",
    "        data_dict[experiment_name] = {}\n",
    "        data_dict[experiment_name]['run_info'] = {\n",
    "            'system': system,\n",
    "            'filesystem': filesystem,\n",
    "            'date': 'mar2022',\n",
    "            'gpu': gpu,\n",
    "            'numGpus': 1,\n",
    "            'numCpus': 1,\n",
    "            'mem': np.nan,\n",
    "            'epochs': 2,\n",
    "            'path': np.nan\n",
    "        }\n",
    "        # timer df\n",
    "        timer_df = row.drop('experiment').to_frame().reset_index()\n",
    "        timer_df.columns = ['timer', 'time']\n",
    "\n",
    "        data_dict[experiment_name]['timer_df'] = timer_df\n",
    "\n",
    "        # gpu df\n",
    "        data_dict[experiment_name]['gpu_df'] = None    \n",
    "    rtx3090 = pd.read_csv(os.path.join(archive,'rtx3090_data.csv'))\n",
    "    for i, row in rtx3090.iterrows():\n",
    "        row = row.drop('Unnamed: 0')\n",
    "        gpu = 'rtx3090'\n",
    "        system = 'personal_pc_g'\n",
    "        filesystem = 'personal_pc_g'\n",
    "        epochs = row['epochs']\n",
    "        experiment_name = f'mar2022_rtx3090_personal_{epochs}.{system}.{filesystem}.{date}'\n",
    "        # run info\n",
    "        data_dict[experiment_name] = {}\n",
    "        data_dict[experiment_name]['run_info'] = {\n",
    "            'system': system,\n",
    "            'filesystem': filesystem,\n",
    "            'date': 'mar2022',\n",
    "            'gpu': gpu,\n",
    "            'numGpus': 1,\n",
    "            'numCpus': 1,\n",
    "            'mem': np.nan,\n",
    "            'epochs': epochs,\n",
    "            'path': np.nan\n",
    "        }\n",
    "        timer_df = row.drop('epochs').to_frame().reset_index()\n",
    "        timer_df.columns = ['timer','time']\n",
    "        data_dict[experiment_name]['timer_df'] = timer_df\n",
    "\n",
    "        # gpu df\n",
    "        data_dict[experiment_name]['gpu_df'] = None    \n",
    "\n",
    "else:\n",
    "    print('No archived data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a3b0ea",
   "metadata": {},
   "source": [
    "### Create pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7a9e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = os.path.join(cwd,'experiment_data.pkl')\n",
    "with open(pickle_file, 'wb') as f:\n",
    "    pickle.dump(data_dict, f)     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
