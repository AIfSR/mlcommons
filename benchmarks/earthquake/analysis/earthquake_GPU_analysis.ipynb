{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec00aeff",
   "metadata": {},
   "source": [
    "# MLCommons Earthquake GPU Analysis Notebook\n",
    "- Creates Pickle file with data for all available runs\n",
    "- Generates GPU Events Graphs\n",
    "- Generates GPU Power Usage Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f208f1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import pickle\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "import matplotlib.dates as md\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247a66ca",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- Make paths smarter ex. if 'card_name_' in dir save there, else higher level\n",
    "- Add NNSE stuff\n",
    "- Create total time plots\n",
    "- Do data analysis for just training time\n",
    "- take advantage of run_info dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aef3d5",
   "metadata": {},
   "source": [
    "### Data Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d4081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_gpu_log(path):\n",
    "    \"\"\" Format the gpu data log into dataframe.\n",
    "\n",
    "    Args:\n",
    "        path: file path for the gpu log.\n",
    "    Returns:\n",
    "        dataframe with gpu data.\n",
    "    \"\"\"\n",
    "    # read in data\n",
    "    gpu_df = pd.read_csv(path, skiprows=1,header=None,low_memory=False)\n",
    "    \n",
    "    # get headers\n",
    "    header = gpu_df.loc[0]\n",
    "    header = header.str[2:].str.strip()\n",
    "    gpu_df = gpu_df.drop(index = [0]).reset_index(drop=True)\n",
    "    gpu_df= gpu_df.set_axis(header,axis=1,inplace=False)\n",
    "    \n",
    "    # set types\n",
    "    int_col = list(gpu_df.columns[1:-1])\n",
    "    gpu_df[int_col] = gpu_df[int_col].astype('int')\n",
    "    float_col = list(gpu_df.columns[-1:])\n",
    "    gpu_df[float_col] = gpu_df[float_col].astype('float')\n",
    "    time_col = list(gpu_df.columns[:1])[0]\n",
    "\n",
    "    gpu_df = gpu_df.groupby('time').mean().reset_index()\n",
    "    \n",
    "    return gpu_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b9ab50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timer_data(err_path):\n",
    "    \"\"\" Collect timer data from run output and create dataframe and csv.\n",
    "\n",
    "    Args:\n",
    "        path: file path for the run log.\n",
    "    Returns:\n",
    "        dataframe with timer data.\n",
    "    \"\"\"   \n",
    "    def index_containing_substring(the_list, substring, _not=False):\n",
    "        index = []\n",
    "        for i, s in enumerate(the_list):\n",
    "            if not _not:\n",
    "                if substring in s:\n",
    "                    index.append(i)\n",
    "            else:\n",
    "                if substring not in s:\n",
    "                    index.append(i)\n",
    "        if _not:\n",
    "            return index\n",
    "        elif substring == '# csv,RUN_STOP':\n",
    "            return index[-2] + 1\n",
    "        elif not index is None:\n",
    "            return index[-1]\n",
    "        return -1    \n",
    "\n",
    "    directory = err_path.rsplit(\"/\",1)[0]\n",
    "    output_path = os.path.join(directory,'timer.csv')\n",
    "    \n",
    "    # read in data\n",
    "    with open(err_path) as f:\n",
    "        content = f.readlines()\n",
    "    \n",
    "    # get timer content\n",
    "    start = index_containing_substring(content, '# csv,timer,status,time,sum,start,tag,msg,uname.node,user,uname.system,platform.version')\n",
    "    stop = index_containing_substring(content, '# csv,RUN_STOP')\n",
    "    if stop == -1:\n",
    "        print(f'Incomplete Run: {directory}')\n",
    "        return None\n",
    "    content = content[start:stop]\n",
    "    neg = index_containing_substring(content, '# csv', _not=True)\n",
    "    \n",
    "    for x in range(min(neg),max(neg)+1):\n",
    "        content.pop(min(neg))\n",
    "    # fix for dictionary in csv\n",
    "    fixed = ''.join(content[min(neg):max(neg)+1]).strip().replace('\\n','').replace('\\s+','').replace('\\t+','')\n",
    "\n",
    "    # formatting\n",
    "    times = []\n",
    "    for x in content:\n",
    "        times.append(x.strip('\\n').replace('# csv,',''))\n",
    "    times[min(neg)-1] = times[min(neg)-1]+fixed\n",
    "    data = []\n",
    "    for x in times:\n",
    "        x = re.sub(\"\\{[^}]*\\}\", lambda x:x.group(0).replace(',',';'), x)\n",
    "        data.append(x)\n",
    "    \n",
    "    # save off data\n",
    "    pd.DataFrame(data)[0].str.split(',', expand=True).to_csv(output_path, index=False)\n",
    "    df = pd.read_csv(output_path, header=1, sep=',', engine='python')\n",
    "\n",
    "    # convert to datetime\n",
    "    df['start'] = pd.to_datetime(df['start'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # get end time\n",
    "    for i, row in df.iterrows():\n",
    "        df.loc[i,'end'] = row['start'] + datetime.timedelta(seconds=row.time)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75409c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_power_data(data_dict):\n",
    "    \"\"\" Convert gpu dataframe into data for plots.\n",
    "    Args:\n",
    "        data_dict: dictionary of run data. \n",
    "    Returns:\n",
    "        dataframe with power data.\n",
    "    \"\"\"   \n",
    "    # setup\n",
    "    data = {}\n",
    "    rename = {\n",
    "        '# time': 'time',\n",
    "        'id': 'id',\n",
    "        'gpu_util %': 'gpu_util',\n",
    "        'memory_util %': 'memory_util',\n",
    "        'encoder_util %': 'encoder_util',\n",
    "        'decoder_util %': 'decoder_util',\n",
    "        'gpu_temp C': 'gpu_temp',\n",
    "        'power_draw W': 'power_draw'\n",
    "    }\n",
    "    \n",
    "    # collect run info\n",
    "    data['gpu'] = data_dict['run_info']['gpu']\n",
    "    data['numGpus'] = data_dict['run_info']['numGpus']\n",
    "    data['numCpus'] = data_dict['run_info']['numCpus']\n",
    "    data['mem'] = data_dict['run_info']['mem']\n",
    "    data['epochs'] = data_dict['run_info']['epochs']\n",
    "    \n",
    "    # build power data\n",
    "    gpu_df = data_dict['gpu_df'].rename(columns=rename)\n",
    "    grouped = gpu_df.groupby(['time']).mean()['power_draw'].reset_index()       \n",
    "    data['kWh'] = sum(grouped['power_draw'])*(1/3600)*(1/1000)\n",
    "    data = pd.DataFrame([data], columns=data.keys())\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ec8b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_NNSE_data(err_path):\n",
    "    with open(err_path) as f:\n",
    "        lines = f.readlines()\n",
    "    NNSE_lines = []\n",
    "    for line in lines:\n",
    "        if 'NNSE \\n' in line:\n",
    "            line = line.replace(\"\\n\", \"\").strip()\n",
    "            NNSE_lines.append(line)\n",
    "            num = 5\n",
    "        elif num != 0:\n",
    "            NNSE_clean = NNSE.replace(\"\\n\", \"\").strip()\n",
    "            lis.append(NNSE_clean)\n",
    "            num -= 1\n",
    "            if num == 0:\n",
    "                full_lis.append(lis)\n",
    "                lis = []\n",
    "    import pdb; pdb.set_trace()\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3119816b",
   "metadata": {},
   "source": [
    "### Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de645a11",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# formatting dictionary for event plot\n",
    "timers_dict = {\n",
    " 'EVAL':{\n",
    "     'hatch':None, \n",
    "     'facecolor':\"none\", \n",
    "     'edgecolor':None,'rename':None, \n",
    "     'color':'tab:blue', \n",
    "     'alpha':0.15\n",
    " },\n",
    " 'CELL_READ_DATA':{\n",
    "     'hatch':'//',\n",
    "     'facecolor':\"none\",\n",
    "     'edgecolor':'black',\n",
    "     'rename':None,\n",
    "     'color':None,\n",
    "     'alpha':0.7\n",
    " },\n",
    " 'data head setup':{\n",
    "     'hatch':None, \n",
    "     'facecolor':\"none\", \n",
    "     'edgecolor':None,\n",
    "     'rename':None,\n",
    "     'color':'tab:green',\n",
    "     'alpha':0.15\n",
    " },\n",
    " 'legal sampling location':{\n",
    "     'hatch':'\\\\\\\\', \n",
    "     'facecolor':\"none\",\n",
    "     'edgecolor':'black',\n",
    "     'rename':None,\n",
    "     'color':None,\n",
    "     'alpha':0.7\n",
    " },\n",
    " 'RunTFTCustomVersion bestfit finalize TFTTestpredict':{\n",
    "     'hatch':None, \n",
    "     'facecolor':\"none\", \n",
    "     'edgecolor':None,\n",
    "     'rename':'TFTTestpredict',\n",
    "     'color':'tab:cyan',\n",
    "     'alpha':0.15\n",
    " },\n",
    " 'RunTFTCustomVersion bestfit finalize VisualizeTFT TFTSaveandInterpret setFFFFmapping':{\n",
    "     'hatch':None,\n",
    "     'facecolor':\"none\",\n",
    "     'edgecolor':None,\n",
    "     'rename':'setFFFFmapping',\n",
    "     'color':'tab:purple',\n",
    "     'alpha':0.15\n",
    " },\n",
    " 'RunTFTCustomVersion bestfit finalize VisualizeTFT DLprediction':{\n",
    "     'hatch':None,\n",
    "     'facecolor':\"none\",\n",
    "     'edgecolor':None,\n",
    "     'rename':'DLprediction',\n",
    "     'color':'tab:orange',\n",
    "     'alpha':0.15\n",
    " }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e967b687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gpu_events(timer_df, gpu_df, epochs, name, path):\n",
    "    \"\"\" Create gpu events plot and save figure.\n",
    "    Args:\n",
    "        timer_df: timer dataframe. \n",
    "        gpu_df: gpu log dataframe.\n",
    "        epochs: number of epochs.\n",
    "        name: run name.\n",
    "        path: output path.\n",
    "    \"\"\"   \n",
    "    # initialize\n",
    "    event_times_dir = os.path.join(path,'event_times')\n",
    "    fig = plt.figure(facecolor='white')\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    # get epoch data\n",
    "    num_epochs = int(epochs)\n",
    "    epoch_timers = []\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_times = [x for x in timer_df['timer'] if f'Epoch:{epoch}' in x]\n",
    "        end_time = max(timer_df[timer_df['timer'].isin(epoch_times)]['end'])\n",
    "        timer_df.loc[timer_df['timer'] == f'RunTFTCustomVersion train Epoch:{epoch}', 'end'] = end_time\n",
    "        timer_df.loc[timer_df['timer'] == f'RunTFTCustomVersion train Epoch:{epoch}', 'timer'] = f'Epoch:{epoch}'\n",
    "        epoch_timers.append(f'Epoch:{epoch}')\n",
    "    epoch_alpha = 0.2\n",
    "    alpha_inc = (0.7)/num_epochs\n",
    "    \n",
    "    # select columns of interest    \n",
    "    timers = list(timers_dict.keys()) + epoch_timers\n",
    "    event_df = timer_df[timer_df['timer'].isin(timers)]\n",
    "    \n",
    "    # find time delta\n",
    "    delta = min(event_df['start']) - min(gpu_df.reset_index()['time'])\n",
    "\n",
    "    # create plot of each event\n",
    "    ax.plot(gpu_df['time'], gpu_df['power_draw W'], color='black', linewidth=0.75)\n",
    "    for i, row in event_df.iterrows():\n",
    "        start_time = row['start'] - delta.round('1h')\n",
    "        end_time = row['end'] - delta.round('1h')\n",
    "        if 'Epoch:' in row['timer']:\n",
    "            ax.axvspan(start_time, end_time,\n",
    "                        alpha=epoch_alpha,\n",
    "                        label=row['timer'],\n",
    "                        color='tab:red')\n",
    "            epoch_alpha += alpha_inc\n",
    "        else:\n",
    "            timer_style = timers_dict[row['timer']]\n",
    "            if timer_style['rename'] is not None:\n",
    "                row['timer'] = timer_style['rename']\n",
    "            ax.axvspan(start_time, end_time, \n",
    "                        alpha=timer_style['alpha'], label=row['timer'], \n",
    "                        hatch=timer_style['hatch'], facecolor=timer_style['facecolor'], \n",
    "                        edgecolor=timer_style['edgecolor'], \n",
    "                        color=timer_style['color'])\n",
    "    # annotations\n",
    "    #import pdb; pdb.set_trace()\n",
    "    annotation_epoch = num_epochs-2\n",
    "    sample = timer_df[timer_df['timer'] == f'RunTFTCustomVersion validation bestfit Epoch:{annotation_epoch}']\n",
    "    annotation_height = 1.13\n",
    "    start_time = sample['start'] - delta.round('1h')\n",
    "    end_time = sample['end'] - delta.round('1h')\n",
    "    filtered = gpu_df[(gpu_df['time'] >= start_time.values[0]) & (gpu_df['time'] <= end_time.values[0])]\n",
    "    watts = filtered.loc[filtered['power_draw W'].idxmax()]['power_draw W']\n",
    "    time = filtered.loc[filtered['power_draw W'].idxmax()]['time']\n",
    "    plt.annotate('validation/bestfit', \n",
    "                 xy=(time,watts), \n",
    "                 xytext=(time+timedelta(hours=1), max(gpu_df['power_draw W'])*annotation_height),\n",
    "                 xycoords='data',\n",
    "                 horizontalalignment=\"left\", verticalalignment='center',\n",
    "                 #connectionstyle='angle,angleA=-90,angleB=10,rad=5'\n",
    "                 arrowprops=dict(arrowstyle='->',lw=1, connectionstyle=\"arc,angleB=70,armA=0,armB=20\"))\n",
    "    annotation_height = annotation_height - 0.1   \n",
    "    \n",
    "    # plot formatting\n",
    "    plt.title(f'{name} Event Times')  \n",
    "    ax.set_ylabel(f'Watts')\n",
    "    ax.set_xlabel(f'Execution Time (Hours)')\n",
    "    ax.set_ylim(0,max(gpu_df['power_draw W'])*1.25)\n",
    "    ax.legend(bbox_to_anchor=(1.01, 1), loc='upper left')\n",
    "    ax.xaxis.set_major_locator(md.MinuteLocator(byminute = [0, 30]))\n",
    "    ax.xaxis.set_major_formatter(md.DateFormatter('%H:%M'))\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation = 90)\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.show()\n",
    "    \n",
    "    # save figure\n",
    "    if not os.path.exists(event_times_dir):\n",
    "        os.mkdir(event_times_dir)\n",
    "    save_name = os.path.join(event_times_dir,f'{name}.png')\n",
    "    fig.savefig(save_name, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41306ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_power_usage(df, path):\n",
    "    \"\"\" Create power usage plot and save figure.\n",
    "    Args:\n",
    "        df: power dataframe. \n",
    "        path: output path.\n",
    "    \"\"\"   \n",
    "    power_usage_dir = os.path.join(path,'power_usage')\n",
    "    name = path.rsplit('/',1)[1]\n",
    "    if not os.path.exists(power_usage_dir):\n",
    "        os.mkdir(power_usage_dir)\n",
    "    df['epochs'] = df['epochs'].astype(int)\n",
    "    df.sort_values('epochs')   \n",
    "    plt.rcParams['figure.figsize'] = [10, 5]\n",
    "    \n",
    "    sns.barplot(x='epochs', y='kWh', hue='gpu',data=df) \n",
    "    plt.title('Epochs vs. kWh per GPU')\n",
    "    \n",
    "    save_name = os.path.join(power_usage_dir,f'{name}_epoch_vs_watts.png')\n",
    "    plt.savefig(save_name)\n",
    "    plt.show()\n",
    "    \n",
    "    # clear plot\n",
    "    plt.clf()\n",
    "    \n",
    "    # kWh per Epoch plot\n",
    "    save_name = os.path.join(power_usage_dir,f'{name}_kWh_per_epoch.png')\n",
    "    df['kWh/epoch'] = df['kWh']/df['epochs']\n",
    "    sns.barplot(x='epochs', y='kWh/epoch', hue='gpu',data=df) \n",
    "    plt.title('kWh/Epoch vs. GPU')\n",
    "    plt.savefig(save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77fe7c1",
   "metadata": {},
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de88e892",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# find run directories\n",
    "cwd = os.getcwd()\n",
    "directories = [os.path.join(cwd,x) for x in os.listdir(cwd) if os.path.isdir(x)]\n",
    "\n",
    "data_dict = {}\n",
    "for path in directories:\n",
    "    experiment_path = [os.path.join(path,x) for x in os.listdir(path) if 'card_name_' in x]\n",
    "    for experiment in experiment_path:\n",
    "            if '_output' in os.listdir(experiment):\n",
    "                log_path = glob.glob(os.path.join(experiment,'*.err'))[0]\n",
    "                if not os.path.exists(log_path):\n",
    "                    continue\n",
    "                timer_df = get_timer_data(log_path)\n",
    "                if timer_df is None:\n",
    "                    continue\n",
    "                #nsse_df = get_NNSE_data(log_path)\n",
    "                experiment_name = experiment.split('/')[-1]\n",
    "                gpu_log = os.path.join(experiment,'_output/images/Outputs/gpu0.log')\n",
    "                gpu_df = format_gpu_log(gpu_log)\n",
    "                if gpu_df is None:\n",
    "                    continue\n",
    "                data_dict[experiment_name] = {}\n",
    "                \n",
    "                # add run info to dictionary\n",
    "                data_dict[experiment_name]['run_info'] = {\n",
    "                    'gpu': experiment_name.split('_')[2],\n",
    "                    'numGpus': experiment_name.split('_')[5],\n",
    "                    'numCpus': experiment_name.split('_')[8],\n",
    "                    'mem': experiment_name.split('_')[10],\n",
    "                    'epochs': experiment_name.split('_')[-1],\n",
    "                    'path': experiment\n",
    "                }\n",
    "                \n",
    "                # add DataFrames to dictionary\n",
    "                data_dict[experiment_name]['gpu_df'] = gpu_df\n",
    "                data_dict[experiment_name]['timer_df'] = timer_df\n",
    "\n",
    "# create pickle file\n",
    "pickle_file = os.path.join(cwd,'gpu_dictionary.pkl')\n",
    "with open(pickle_file, 'wb') as f:\n",
    "    pickle.dump(data_dict, f)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ca4a35",
   "metadata": {},
   "source": [
    "### Load Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d014e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_file, 'rb') as f:\n",
    "    loaded_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3069e96d",
   "metadata": {},
   "source": [
    "### Create Analysis Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0022b081",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "power_df = pd.DataFrame()\n",
    "for experiment in loaded_dict.keys():\n",
    "        path = loaded_dict[experiment]['run_info']['path']\n",
    "        epochs = loaded_dict[experiment]['run_info']['epochs']\n",
    "        dir_path = path.rsplit('/',1)[0]\n",
    "        plot_path = os.path.join(dir_path,'analysis')\n",
    "        if not os.path.exists(plot_path):\n",
    "            os.mkdir(plot_path)\n",
    "        timer_df = loaded_dict[experiment]['timer_df']\n",
    "        gpu_df = loaded_dict[experiment]['gpu_df']\n",
    "        gpu_df['time'] = pd.to_datetime(gpu_df['time'].str.split(\".\").str[0],format='%Y-%m-%d%H:%M:%S')\n",
    "        plot_gpu_events(timer_df, gpu_df, epochs, experiment, plot_path)\n",
    "        power_data = get_power_data(loaded_dict[experiment])\n",
    "        power_df = pd.concat([power_df,power_data])\n",
    "\n",
    "plot_power_usage(power_df, plot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0400e06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
