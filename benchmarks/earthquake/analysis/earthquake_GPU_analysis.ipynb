{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d45feb1",
   "metadata": {},
   "source": [
    "# MLCommons Earthquake GPU Analysis Notebook\n",
    "- Creates Pickle file with data for all available runs\n",
    "- Generates GPU Events Graphs\n",
    "- Generates GPU Power Usage Graphs\n",
    "- Generates GPU Execution Time Comparison Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39d100c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import pickle\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "import matplotlib.dates as md\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbe89c5",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- Make paths smarter ex. if 'card_name_' in dir save there, else higher level\n",
    "- Add NNSE stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e47cb2",
   "metadata": {},
   "source": [
    "### Data Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a15fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_gpu_log(path):\n",
    "    \"\"\" Format the gpu data log into dataframe.\n",
    "\n",
    "    Args:\n",
    "        path: file path for the gpu log.\n",
    "    Returns:\n",
    "        dataframe with gpu data.\n",
    "    \"\"\"\n",
    "    # read in data\n",
    "    gpu_df = pd.read_csv(path, skiprows=1,header=None,low_memory=False)\n",
    "    \n",
    "    # get headers\n",
    "    header = gpu_df.loc[0]\n",
    "    header = header.str[2:].str.strip()\n",
    "    gpu_df = gpu_df.drop(index = [0]).reset_index(drop=True)\n",
    "    gpu_df= gpu_df.set_axis(header,axis=1,inplace=False)\n",
    "    \n",
    "    # set types\n",
    "    int_col = list(gpu_df.columns[1:-1])\n",
    "    gpu_df[int_col] = gpu_df[int_col].astype('int')\n",
    "    float_col = list(gpu_df.columns[-1:])\n",
    "    gpu_df[float_col] = gpu_df[float_col].astype('float')\n",
    "    time_col = list(gpu_df.columns[:1])[0]\n",
    "\n",
    "    gpu_df = gpu_df.groupby('time').mean().reset_index()\n",
    "    \n",
    "    return gpu_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b915a056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timer_data(err_path):\n",
    "    \"\"\" Collect timer data from run output and create dataframe and csv.\n",
    "\n",
    "    Args:\n",
    "        path: file path for the run log.\n",
    "    Returns:\n",
    "        dataframe with timer data.\n",
    "    \"\"\"   \n",
    "    def index_containing_substring(the_list, substring, _not=False):\n",
    "        index = []\n",
    "        for i, s in enumerate(the_list):\n",
    "            if not _not:\n",
    "                if substring in s:\n",
    "                    index.append(i)\n",
    "            else:\n",
    "                if substring not in s:\n",
    "                    index.append(i)\n",
    "        if _not:\n",
    "            return index\n",
    "        elif substring == '# csv,RUN_STOP':\n",
    "            if len(index) < 2:\n",
    "                return -1\n",
    "            return index[-2] + 1\n",
    "        elif not index is None:\n",
    "            return index[-1]\n",
    "        return -1    \n",
    "\n",
    "    directory = err_path.rsplit(\"/\",1)[0]\n",
    "    output_path = os.path.join(directory,'timer.csv')\n",
    "    \n",
    "    # read in data\n",
    "    with open(err_path) as f:\n",
    "        content = f.readlines()\n",
    "    \n",
    "    # get timer content\n",
    "    start = index_containing_substring(content, '# csv,timer,status,time,sum,start,tag,msg,uname.node,user,uname.system,platform.version')\n",
    "    stop = index_containing_substring(content, '# csv,RUN_STOP')\n",
    "    if stop == -1:\n",
    "        print(f'Incomplete Run: {directory}')\n",
    "        return None\n",
    "    content = content[start:stop]\n",
    "    neg = index_containing_substring(content, '# csv', _not=True)\n",
    "    \n",
    "    # fix for dictionary in csv\n",
    "    fixed = ''.join(content[min(neg):max(neg)+1]).strip().replace('\\n','').replace('\\s+','').replace('\\t+','')\n",
    "    for x in range(min(neg),max(neg)+1):\n",
    "        content.pop(min(neg))\n",
    "\n",
    "    # formatting\n",
    "    times = []\n",
    "    for x in content:\n",
    "        times.append(x.strip('\\n').replace('# csv,',''))\n",
    "    times[min(neg)-1] = times[min(neg)-1]+fixed\n",
    "    data = []\n",
    "    for x in times:\n",
    "        x = re.sub(\"\\{[^}]*\\}\", lambda x:x.group(0).replace(',',';'), x)\n",
    "        data.append(x)\n",
    "    \n",
    "    # save off data\n",
    "    pd.DataFrame(data)[0].str.split(',', expand=True).to_csv(output_path, index=False)\n",
    "    df = pd.read_csv(output_path, header=1, sep=',', engine='python')\n",
    "\n",
    "    # convert to datetime\n",
    "    df['start'] = pd.to_datetime(df['start'], format='%Y-%m-%d %H:%M:%S')\n",
    "    df = df[df['status'] != 'failed']\n",
    "    \n",
    "    # get end time\n",
    "    for i, row in df.iterrows():\n",
    "        df.loc[i,'end'] = row['start'] + datetime.timedelta(seconds=float(row.time))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae50d7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_power_data(data_dict):\n",
    "    \"\"\" Convert gpu dataframe into data for plots.\n",
    "    Args:\n",
    "        data_dict: dictionary of run data. \n",
    "    Returns:\n",
    "        dataframe with power data.\n",
    "    \"\"\"   \n",
    "    # setup\n",
    "    data = {}\n",
    "    rename = {\n",
    "        '# time': 'time',\n",
    "        'id': 'id',\n",
    "        'gpu_util %': 'gpu_util',\n",
    "        'memory_util %': 'memory_util',\n",
    "        'encoder_util %': 'encoder_util',\n",
    "        'decoder_util %': 'decoder_util',\n",
    "        'gpu_temp C': 'gpu_temp',\n",
    "        'power_draw W': 'power_draw'\n",
    "    }\n",
    "    \n",
    "    # collect run info\n",
    "    data['gpu'] = data_dict['run_info']['gpu']\n",
    "    data['numGpus'] = data_dict['run_info']['numGpus']\n",
    "    data['numCpus'] = data_dict['run_info']['numCpus']\n",
    "    data['mem'] = data_dict['run_info']['mem']\n",
    "    data['epochs'] = data_dict['run_info']['epochs']\n",
    "    \n",
    "    # build power data total notebook\n",
    "    gpu_df = data_dict['gpu_df'].rename(columns=rename)\n",
    "    grouped = gpu_df.groupby(['time']).mean()['power_draw'].reset_index()       \n",
    "    data['kWh_total'] = sum(grouped['power_draw'])*(1/3600)*(1/1000)\n",
    "    data = pd.DataFrame([data], columns=data.keys())\n",
    "    \n",
    "    # build power data model fit\n",
    "    timer_df = data_dict['timer_df']\n",
    "    delta = min(timer_df['start']) - min(grouped['time']).round('1h')\n",
    "    fit_event = timer_df.loc[timer_df['timer'] == 'RunTFTCustomVersion train']\n",
    "    fit_start = fit_event['start'] - delta\n",
    "    fit_end = fit_event['end'] - delta\n",
    "    fit_grouped = grouped[(grouped['time'] >= fit_start.values[0]) & (grouped['time'] <= fit_end.values[0])]\n",
    "    data['kWh_fit'] = sum(fit_grouped['power_draw'])*(1/3600)*(1/1000)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6838d040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_NNSE_data(err_path):\n",
    "    with open(err_path) as f:\n",
    "        lines = f.readlines()\n",
    "    NNSE_lines = []\n",
    "    for line in lines:\n",
    "        if 'NNSE \\n' in line:\n",
    "            line = line.replace(\"\\n\", \"\").strip()\n",
    "            NNSE_lines.append(line)\n",
    "            num = 5\n",
    "        elif num != 0:\n",
    "            NNSE_clean = NNSE.replace(\"\\n\", \"\").strip()\n",
    "            lis.append(NNSE_clean)\n",
    "            num -= 1\n",
    "            if num == 0:\n",
    "                full_lis.append(lis)\n",
    "                lis = []\n",
    "    import pdb; pdb.set_trace()\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d137680",
   "metadata": {},
   "source": [
    "### Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1a7bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatting dictionary for event plot\n",
    "timers_dict = {\n",
    " 'EVAL':{\n",
    "     'hatch':None, \n",
    "     'facecolor':\"none\", \n",
    "     'edgecolor':None,'rename':None, \n",
    "     'color':'tab:blue', \n",
    "     'alpha':0.15\n",
    " },\n",
    " 'CELL_READ_DATA':{\n",
    "     'hatch':'//',\n",
    "     'facecolor':\"none\",\n",
    "     'edgecolor':'black',\n",
    "     'rename':None,\n",
    "     'color':None,\n",
    "     'alpha':0.7\n",
    " },\n",
    " 'data head setup':{\n",
    "     'hatch':None, \n",
    "     'facecolor':\"none\", \n",
    "     'edgecolor':None,\n",
    "     'rename':None,\n",
    "     'color':'tab:green',\n",
    "     'alpha':0.15\n",
    " },\n",
    " 'legal sampling location':{\n",
    "     'hatch':'\\\\\\\\', \n",
    "     'facecolor':\"none\",\n",
    "     'edgecolor':'black',\n",
    "     'rename':None,\n",
    "     'color':None,\n",
    "     'alpha':0.7\n",
    " },\n",
    " 'RunTFTCustomVersion bestfit finalize TFTTestpredict':{\n",
    "     'hatch':None, \n",
    "     'facecolor':\"none\", \n",
    "     'edgecolor':None,\n",
    "     'rename':'TFTTestpredict',\n",
    "     'color':'tab:cyan',\n",
    "     'alpha':0.15\n",
    " },\n",
    " 'RunTFTCustomVersion bestfit finalize VisualizeTFT TFTSaveandInterpret setFFFFmapping':{\n",
    "     'hatch':None,\n",
    "     'facecolor':\"none\",\n",
    "     'edgecolor':None,\n",
    "     'rename':'setFFFFmapping',\n",
    "     'color':'tab:purple',\n",
    "     'alpha':0.15\n",
    " },\n",
    " 'RunTFTCustomVersion bestfit finalize VisualizeTFT DLprediction':{\n",
    "     'hatch':None,\n",
    "     'facecolor':\"none\",\n",
    "     'edgecolor':None,\n",
    "     'rename':'DLprediction',\n",
    "     'color':'tab:orange',\n",
    "     'alpha':0.15\n",
    " },\n",
    " 'DLResults_Graphs':{\n",
    "     'hatch':None,\n",
    "     'facecolor':\"none\",\n",
    "     'edgecolor':None,\n",
    "     'rename':'DLResults_Graphs',\n",
    "     'color':'tab:olive',\n",
    "     'alpha':0.15\n",
    " }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53902dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gpu_events(timer_df, gpu_df, epochs, name, path, zoom=False):\n",
    "    \"\"\" Create gpu events plot and save figure.\n",
    "    Args:\n",
    "        timer_df: timer dataframe. \n",
    "        gpu_df: gpu log dataframe.\n",
    "        epochs: number of epochs.\n",
    "        name: run name.\n",
    "        path: output path.\n",
    "        zoom: optional arg for zooming on event\n",
    "    \"\"\"   \n",
    "    # initialize\n",
    "    event_times_dir = os.path.join(path,'event_times')\n",
    "    if not zoom == False:\n",
    "        name = f'{name}_zoomed_{zoom}'\n",
    "    fig = plt.figure(facecolor='white')\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    # get epoch data\n",
    "    num_epochs = int(epochs)\n",
    "    epoch_timers = []\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_times = [x for x in timer_df['timer'] if f'Epoch:{epoch}' in x]\n",
    "        end_time = max(timer_df[timer_df['timer'].isin(epoch_times)]['end'])\n",
    "        timer_df.loc[timer_df['timer'] == f'RunTFTCustomVersion train Epoch:{epoch}', 'end'] = end_time\n",
    "        timer_df.loc[timer_df['timer'] == f'RunTFTCustomVersion train Epoch:{epoch}', 'timer'] = f'Epoch:{epoch}'\n",
    "        epoch_timers.append(f'Epoch:{epoch}')\n",
    "    epoch_alpha = 0.2\n",
    "    alpha_inc = (0.7)/num_epochs\n",
    "    \n",
    "    # select columns of interest    \n",
    "    timers = list(timers_dict.keys()) + epoch_timers\n",
    "    event_df = timer_df[timer_df['timer'].isin(timers)]\n",
    "    \n",
    "    # find time delta\n",
    "    delta = min(event_df['start']) - min(gpu_df.reset_index()['time'])\n",
    "\n",
    "    # create plot of each event\n",
    "    ax.plot(gpu_df['time'], gpu_df['power_draw W'], color='black', linewidth=0.75)\n",
    "    for i, row in event_df.iterrows():\n",
    "        start_time = row['start'] - delta.round('1h')\n",
    "        end_time = row['end'] - delta.round('1h')\n",
    "        if 'Epoch:' in row['timer']:\n",
    "            ax.axvspan(start_time, end_time,\n",
    "                        alpha=epoch_alpha,\n",
    "                        label=row['timer'],\n",
    "                        color='tab:red')\n",
    "            epoch_alpha += alpha_inc\n",
    "        else:\n",
    "            timer_style = timers_dict[row['timer']]\n",
    "            if timer_style['rename'] is not None:\n",
    "                row['timer'] = timer_style['rename']\n",
    "            if zoom == False:\n",
    "                label= row['timer']\n",
    "            else:\n",
    "                label = '_nolegend_'\n",
    "            ax.axvspan(start_time, end_time, \n",
    "                        alpha=timer_style['alpha'], label=label, \n",
    "                        hatch=timer_style['hatch'], facecolor=timer_style['facecolor'], \n",
    "                        edgecolor=timer_style['edgecolor'], \n",
    "                        color=timer_style['color'])\n",
    "    # annotations\n",
    "    annotation_epoch = num_epochs-2\n",
    "    sample = timer_df[timer_df['timer'] == f'RunTFTCustomVersion validation bestfit Epoch:{annotation_epoch}']\n",
    "    annotation_height = 1.13\n",
    "    start_time = sample['start'] - delta.round('1h')\n",
    "    end_time = sample['end'] - delta.round('1h')\n",
    "    filtered = gpu_df[(gpu_df['time'] >= start_time.values[0]) & (gpu_df['time'] <= end_time.values[0])]\n",
    "    watts = filtered.loc[filtered['power_draw W'].idxmax()]['power_draw W']\n",
    "    time = filtered.loc[filtered['power_draw W'].idxmax()]['time']\n",
    "    \n",
    "    # make annotations zoom dependent\n",
    "    if zoom == False:\n",
    "        plt.annotate('validation/bestfit', \n",
    "                     xy=(time,watts), \n",
    "                     xytext=(time+timedelta(hours=1), max(gpu_df['power_draw W'])*annotation_height),\n",
    "                     xycoords='data',\n",
    "                     horizontalalignment=\"left\", verticalalignment='center',\n",
    "                     #connectionstyle='angle,angleA=-90,angleB=10,rad=5'\n",
    "                     arrowprops=dict(arrowstyle='->',lw=1, connectionstyle=\"arc,angleB=70,armA=0,armB=20\"))\n",
    "    elif zoom == 'validation':\n",
    "        row = timer_df.loc[timer_df['timer'] == f'RunTFTCustomVersion validation bestfit Epoch:{annotation_epoch}']\n",
    "        start_time = row['start'] - delta.round('1h')\n",
    "        end_time = row['end'] - delta.round('1h')\n",
    "        ax.axvspan(start_time, end_time, \n",
    "                    alpha=0.5, label='Validation', \n",
    "                    hatch='////', facecolor='none',\n",
    "                    edgecolor='black',\n",
    "                    color=None)\n",
    "        ax.set_xlim([start_time - timedelta(minutes=3.5) ,end_time + timedelta(minutes=3.5)])\n",
    "    elif zoom == 'DLResults':\n",
    "        row = timer_df.loc[timer_df['timer'] == 'DLResults_Graphs']\n",
    "        start_time = row['start'] - delta.round('1h')\n",
    "        end_time = row['end'] - delta.round('1h')\n",
    "        ax.set_xlim([start_time - timedelta(minutes=3.5) ,end_time + timedelta(minutes=0.5)])\n",
    "    \n",
    "    # plot formatting\n",
    "    plt.title(f'{name} Event Times')  \n",
    "    ax.set_ylabel(f'Watts')\n",
    "    ax.set_xlabel(f'Execution Time (Hours)')\n",
    "    ax.set_ylim(0,max(gpu_df['power_draw W'])*1.25)\n",
    "    ax.legend(bbox_to_anchor=(1.01, 1), loc='upper left')\n",
    "    ax.xaxis.set_major_locator(md.MinuteLocator(byminute = [0, 30]))\n",
    "    ax.xaxis.set_major_formatter(md.DateFormatter('%H:%M'))\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation = 90)\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.show()\n",
    "    \n",
    "    # save figure\n",
    "    if not os.path.exists(event_times_dir):\n",
    "        os.mkdir(event_times_dir)\n",
    "    save_name = os.path.join(event_times_dir,f'{name}.png')\n",
    "    fig.savefig(save_name, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0658355e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_power_usage(df, path):\n",
    "    \"\"\" Create power usage plot and save figure.\n",
    "    Args:\n",
    "        df: power dataframe. \n",
    "        path: output path.\n",
    "    \"\"\"\n",
    "    power_usage_dir = os.path.join(path,'power_usage')\n",
    "    name = path.rsplit('/',1)[1]\n",
    "    if not os.path.exists(power_usage_dir):\n",
    "        os.mkdir(power_usage_dir)\n",
    "    df['epochs'] = df['epochs'].astype(int)\n",
    "    df.sort_values('epochs')   \n",
    "    plt.rcParams['figure.figsize'] = [10, 5]\n",
    "    \n",
    "    # plot total notebook epochs vs. kWh\n",
    "    sns.barplot(x='epochs', y='kWh_total', hue='gpu',data=df) \n",
    "    plt.title('Total Notebook: Epochs vs. kWh')\n",
    "    plt.ylabel('kWh')\n",
    "    save_name = os.path.join(power_usage_dir,f'total_{name}_epoch_vs_watts.png')\n",
    "    plt.savefig(save_name)\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    \n",
    "    # plot total notebook kWh per Epoch plot\n",
    "    save_name = os.path.join(power_usage_dir,f'total_{name}_kWh_per_epoch.png')\n",
    "    df['kWh/epoch_total'] = df['kWh_total']/df['epochs']\n",
    "    sns.barplot(x='epochs', y='kWh/epoch_total', hue='gpu',data=df) \n",
    "    plt.title('Total Notebook: Epochs vs. kWh/Epoch')\n",
    "    plt.ylabel('kWh/epoch')\n",
    "    plt.savefig(save_name)  \n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    \n",
    "    # plot model fit epochs vs. kWh\n",
    "    sns.barplot(x='epochs', y='kWh_fit', hue='gpu',data=df) \n",
    "    plt.title('Model Fit: Epochs vs. kWh') \n",
    "    plt.ylabel('kWh')\n",
    "    save_name = os.path.join(power_usage_dir,f'model_fit_{name}_epoch_vs_watts.png')\n",
    "    plt.savefig(save_name)\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    \n",
    "    # plot model fit kWh per Epoch plot\n",
    "    save_name = os.path.join(power_usage_dir,f'model_fit_{name}_kWh_per_epoch.png')\n",
    "    df['kWh/epoch_fit'] = df['kWh_fit']/df['epochs']\n",
    "    sns.barplot(x='epochs', y='kWh/epoch_fit', hue='gpu',data=df) \n",
    "    plt.title('Model Fit: Epochs vs. kWh/Epoch')\n",
    "    plt.ylabel('kWh/epoch')\n",
    "    plt.savefig(save_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21528ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_times(data_dict, path):\n",
    "    \"\"\" Create plot to compare training times and save figure.\n",
    "    Args:\n",
    "        data_dict: dictionary of run data. \n",
    "        path: output path.\n",
    "    \"\"\"\n",
    "    time_dir = os.path.join(path,'gpu_times')\n",
    "    if not os.path.exists(time_dir):\n",
    "        os.mkdir(time_dir)\n",
    "\n",
    "    time_data = pd.DataFrame(columns=['gpu','epochs','time'])\n",
    "    for experiment in data_dict.keys():\n",
    "        data = pd.DataFrame()            \n",
    "        timer_df = data_dict[experiment]['timer_df']\n",
    "        data['time'] = timer_df.loc[timer_df['timer'] == 'RunTFTCustomVersion train']['time']\n",
    "        data['gpu'] = data_dict[experiment]['run_info']['gpu']\n",
    "        data['epochs'] = data_dict[experiment]['run_info']['epochs']\n",
    "        time_data = pd.concat([time_data, data])\n",
    "    \n",
    "    sns.scatterplot(x='epochs', \n",
    "                 y='time',\n",
    "                 hue='gpu',\n",
    "                 markers='*',\n",
    "                 data=time_data)\n",
    "    plt.title('Training Time Comparison')\n",
    "    plt.ylabel('time (seconds)')\n",
    "    save_name = os.path.join(time_dir,'training_times.png')\n",
    "    plt.savefig(save_name)\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c6e204",
   "metadata": {},
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3d6007",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# find run directories\n",
    "cwd = os.getcwd()\n",
    "directories = [os.path.join(cwd,x) for x in os.listdir(cwd) if os.path.isdir(x)]\n",
    "\n",
    "data_dict = {}\n",
    "for path in directories:\n",
    "    experiment_path = [os.path.join(path,x) for x in os.listdir(path) if 'card_name_' in x]\n",
    "    for experiment in experiment_path:\n",
    "            if '_output' in os.listdir(experiment):\n",
    "                log_path = glob.glob(os.path.join(experiment,'*.err'))[0]\n",
    "                if not os.path.exists(log_path):\n",
    "                    continue\n",
    "                timer_df = get_timer_data(log_path)\n",
    "                if timer_df is None:\n",
    "                    continue\n",
    "                #nsse_df = get_NNSE_data(log_path)\n",
    "                experiment_name = experiment.split('/')[-1]\n",
    "                gpu_log = os.path.join(experiment,'_output/Outputs/gpu0.log')\n",
    "                gpu_df = format_gpu_log(gpu_log)\n",
    "                if gpu_df is None:\n",
    "                    continue\n",
    "                data_dict[experiment_name] = {}\n",
    "                \n",
    "                # add run info to dictionary\n",
    "                data_dict[experiment_name]['run_info'] = {\n",
    "                    'gpu': experiment_name.split('_')[2],\n",
    "                    'numGpus': experiment_name.split('_')[5],\n",
    "                    'numCpus': experiment_name.split('_')[8],\n",
    "                    'mem': experiment_name.split('_')[10],\n",
    "                    'epochs': experiment_name.split('_')[-1],\n",
    "                    'path': experiment\n",
    "                }\n",
    "                \n",
    "                # add DataFrames to dictionary\n",
    "                data_dict[experiment_name]['gpu_df'] = gpu_df\n",
    "                data_dict[experiment_name]['timer_df'] = timer_df\n",
    "\n",
    "# create pickle file\n",
    "pickle_file = os.path.join(cwd,'gpu_dictionary.pkl')\n",
    "with open(pickle_file, 'wb') as f:\n",
    "    pickle.dump(data_dict, f)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7310e13e",
   "metadata": {},
   "source": [
    "### Load Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d86d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_file, 'rb') as f:\n",
    "    loaded_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed688769",
   "metadata": {},
   "source": [
    "### Create Analysis Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f35ef4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "power_df = pd.DataFrame()\n",
    "for experiment in loaded_dict.keys():\n",
    "        path = loaded_dict[experiment]['run_info']['path']\n",
    "        epochs = loaded_dict[experiment]['run_info']['epochs']\n",
    "        dir_path = path.rsplit('/',1)[0]\n",
    "        plot_path = os.path.join(dir_path,'analysis')\n",
    "        if not os.path.exists(plot_path):\n",
    "            os.mkdir(plot_path)\n",
    "        timer_df = loaded_dict[experiment]['timer_df']\n",
    "        gpu_df = loaded_dict[experiment]['gpu_df']\n",
    "        gpu_df['time'] = pd.to_datetime(gpu_df['time'].str.split(\".\").str[0],format='%Y-%m-%d:%H:%M:%S')\n",
    "        plot_gpu_events(timer_df, gpu_df, epochs, experiment, plot_path)\n",
    "        plot_gpu_events(timer_df, gpu_df, epochs, experiment, plot_path, 'validation')\n",
    "        plot_gpu_events(timer_df, gpu_df, epochs, experiment, plot_path, 'DLResults')\n",
    "        power_data = get_power_data(loaded_dict[experiment])\n",
    "        power_df = pd.concat([power_df,power_data])\n",
    "\n",
    "plot_power_usage(power_df, plot_path)\n",
    "plot_train_times(loaded_dict, plot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9053807c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
