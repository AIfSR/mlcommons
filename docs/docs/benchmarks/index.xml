<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ML Science Benchmarks â€“ Benchmarks</title>
    <link>/mlcommons/docs/benchmarks/</link>
    <description>Recent content in Benchmarks on ML Science Benchmarks</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Thu, 05 Jan 2017 00:00:00 +0000</lastBuildDate>
    
	  <atom:link href="/mlcommons/docs/benchmarks/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Docs: CANDLE-UNO</title>
      <link>/mlcommons/docs/benchmarks/candle-uno/</link>
      <pubDate>Thu, 05 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/mlcommons/docs/benchmarks/candle-uno/</guid>
      <description>
        
        
        

&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;p&gt;CANDLE (Exascale Deep Learning and Simulation Enabled Precision Medicine
for Cancer) project aims to implement deep learning architectures that
are relevant to problems in cancer.&lt;/p&gt;

&lt;/div&gt;

&lt;h3 id=&#34;candle-uno&#34;&gt;CANDLE-UNO&lt;/h3&gt;
&lt;p&gt;CANDLE (Exascale Deep Learning and Simulation Enabled Precision Medicine
for Cancer) project aims to implement deep learning architectures that
are relevant to problems in cancer. These architectures address problems
at three biological scales: cellular (Pilot1 P1), molecular (Pilot P2)
and population (Pilot3).&lt;/p&gt;
&lt;p&gt;Pilot1 (P1) benchmarks are formed out of problems and data at the
cellular level. The high level goal of the problem behind the P1
benchmarks is to predict drug response based on molecular features of
tumor cells and drug descriptors. Pilot2 (P2) benchmarks are formed out
of problems and data at the molecular level. The high level goal of the
problem behind the P2 benchmarks is molecular dynamic simulations of
proteins involved in cancer, specifically the RAS protein. Pilot3 (P3)
benchmarks are formed out of problems and data at the population level.
The high level goal of the problem behind the P3 benchmarks is to
predict cancer recurrence in patients based on patient related data.&lt;/p&gt;
&lt;p&gt;Uno application from Pilot1 (P1): The goal of Uno is to predict tumor
response to single and paired drugs, based on molecular features of
tumor cells across multiple data sources. Combined dose response data
contains sources: [&amp;lsquo;CCLE&amp;rsquo; &amp;lsquo;CTRP&amp;rsquo; &amp;lsquo;gCSI&amp;rsquo; &amp;lsquo;GDSC&amp;rsquo; &amp;lsquo;NCI60&amp;rsquo; &amp;lsquo;SCL&amp;rsquo; &amp;lsquo;SCLC&amp;rsquo;
&amp;lsquo;ALMANAC.FG&amp;rsquo; &amp;lsquo;ALMANAC.FF&amp;rsquo; &amp;lsquo;ALMANAC.1A&amp;rsquo;]. Uno implements a deep learning
architecture with 21M parameters in TensorFlow framework in Python. The
code is publicly available on
&lt;a href=&#34;https://github.com/ECP-CANDLE/Benchmarks/tree/develop/Pilot1/Uno&#34;&gt;GitHub&lt;/a&gt;.
The script in this repository downloads all required datasets. The
primary metric to evaluate this applications is throughput (samples per
second). More details on running Uno can be found
&lt;a href=&#34;https://github.com/ECP-CANDLE/Benchmarks/blob/develop/Pilot1/Uno/README.AUC.md&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id=&#34;candle-uno-specific-benchmark-targets&#34;&gt;CANDLE-UNO Specific Benchmark Targets&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Scientific objective(s):
&lt;ul&gt;
&lt;li&gt;Objective: Predictions of tumor response to drug treatments,
based on molecular features of tumor cells and drug descriptors&lt;/li&gt;
&lt;li&gt;Formula: Validation loss&lt;/li&gt;
&lt;li&gt;Score: 0.0054&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data
&lt;ul&gt;
&lt;li&gt;Download:
&lt;a href=&#34;http://ftp.mcs.anl.gov/pub/candle/public/benchmarks/Pilot1/uno/&#34;&gt;http://ftp.mcs.anl.gov/pub/candle/public/benchmarks/Pilot1/uno/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Data Size: 6.4G&lt;/li&gt;
&lt;li&gt;Training samples: 423952&lt;/li&gt;
&lt;li&gt;Validation samples: 52994&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Example implementation
&lt;ul&gt;
&lt;li&gt;Model: Multi-task Learning-based custom model&lt;/li&gt;
&lt;li&gt;Reference Code:
&lt;a href=&#34;https://github.com/ECP-CANDLE/Benchmarks/tree/develop/Pilot1/Uno&#34;&gt;https://github.com/ECP-CANDLE/Benchmarks/tree/develop/Pilot1/Uno&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Run Instructions:
&lt;a href=&#34;https://github.com/ECP-CANDLE/Benchmarks/blob/develop/Pilot1/Uno/README.AUC.md&#34;&gt;https://github.com/ECP-CANDLE/Benchmarks/blob/develop/Pilot1/Uno/README.AUC.md&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Time-to-solution: 10667 samples/sec (batch size 64) on single
A100&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: CloudMask (Segmentation)</title>
      <link>/mlcommons/docs/benchmarks/cloudmask/</link>
      <pubDate>Thu, 05 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/mlcommons/docs/benchmarks/cloudmask/</guid>
      <description>
        
        
        

&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;p&gt;Estimation of sea surface temperature (SST) from space-borne sensors.&lt;/p&gt;

&lt;/div&gt;

&lt;h3 id=&#34;cloudmask-segmentation&#34;&gt;CloudMask (Segmentation)&lt;/h3&gt;
&lt;p&gt;Estimation of sea surface temperature (SST) from space-borne sensors,
such as satellites, is crucial for a number of applications in
environmental sciences. One of the aspects that underpins the derivation
of SST is cloud screening, which is a step that marks each and every
pixel of thousands of satellite imageries as containing cloud or clear
sky, historically performed using either thresholding or Bayesian
methods.&lt;/p&gt;
&lt;p&gt;This benchmark focuses on using a machine learning-based model for
masking clouds, in the Sentinel-3 satellite, which carries the Sea and
Land Surface Temperature Radiometer (SLSTR) instrument. More
specifically, the benchmark operates on multispectral image data. The
example implementation is a variation of the U-Net deep neural network.
The benchmark includes two datasets of DS1-Cloud and DS2-Cloud, with
sizes of 180GB and 4.9TB, respectively. Each dataset is made up of two
parts: reflectance and brightness temperature. The reflectance is
captured across six channels with the resolution of 2400 x 3000 pixels,
and the brightness temperature is captured across three channels with
the resolution of 1200 x 1500 pixels.&lt;/p&gt;
&lt;h4 id=&#34;cloudmask-specific-benchmark-targets&#34;&gt;CloudMask Specific Benchmark Targets&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Scientific objective(s):
&lt;ul&gt;
&lt;li&gt;Objective: Compare the accuracy produced by the Neural Network
with the accuracy of a Bayesian method&lt;/li&gt;
&lt;li&gt;Formula: Weighted Binary Cross Entropy of validation dat&lt;/li&gt;
&lt;li&gt;Score: 0.9 for convergence&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data
&lt;ul&gt;
&lt;li&gt;Download: aws s3 --no-sign-request --endpoint-url
&lt;a href=&#34;https://s3.echo.stfc.ac.uk&#34;&gt;https://s3.echo.stfc.ac.uk&lt;/a&gt; sync s3://sciml-datasets/en/
cloud_slstr_ds1 .&lt;/li&gt;
&lt;li&gt;Data Size: 180GB&lt;/li&gt;
&lt;li&gt;Training samples: 15488&lt;/li&gt;
&lt;li&gt;Validation samples: 3840&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Example implementation
&lt;ul&gt;
&lt;li&gt;Model: U-Net&lt;/li&gt;
&lt;li&gt;Reference Code:
&lt;a href=&#34;https://github.com/stfc-sciml/sciml-bench/tree/master/sciml_bench/benchmarks/slstr_cloud&#34;&gt;https://github.com/stfc-sciml/sciml-bench/tree/master/sciml_bench/benchmarks/slstr_cloud&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Run Instructions:
&lt;a href=&#34;https://github.com/stfc-sciml/sciml-bench/blob/master/README.md&#34;&gt;https://github.com/stfc-sciml/sciml-bench/blob/master/README.md&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Time-to-solution: 180GB dataset runs 59 min on DGX-2 with 32
V100 GPU&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: TEvolOp Earthquake Forecasting</title>
      <link>/mlcommons/docs/benchmarks/earthquake/</link>
      <pubDate>Thu, 05 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/mlcommons/docs/benchmarks/earthquake/</guid>
      <description>
        
        
        

&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;p&gt;Forcatsing Earthquakes&lt;/p&gt;

&lt;/div&gt;

&lt;h3 id=&#34;tevolop-earthquake-forecasting&#34;&gt;TEvolOp Earthquake Forecasting&lt;/h3&gt;
&lt;p&gt;Time series are seen in many scientific problems and many of them are
geospatial &amp;ndash; functions of space and time and this benchmark illustrates
this type. Some time series have a clear spatial structure that for
example strongly relates nearby space points. The problem chosen is
termed a spatial bag where there is spatial variation but it is not
clearly linked to the geometric distance between spatial regions. In
contrast, traffic-related time series have a strong spatial structure.
We intend benchmarks that cover a broad range of problem types.&lt;/p&gt;
&lt;p&gt;The earthquake data comes from USGS and we have chosen a 4 degrees of
Latitude (32 to 36 N) and 6 degrees of Longitude (-120 to -114) region
covering Southern California. The data runs from 1950 to the present day
and is presented as events: magnitude, ground location, depth, and time.
We have divided the data into time and space bins. The time interval is
daily but in our reference models, we accumulate this into fortnightly
data. Southern California is divided into a 40 by 60 grid of 0.1 by
0.1-degree &amp;ldquo;pixels&amp;rdquo; which corresponds roughly to squares with an 11 km
side, The dataset also includes an assignment of pixels to known faults
and a list of the largest earthquakes in that region from 1950 until
today. We have chosen various samplings of the dataset to provide both
input and predicted values. These include time ranges from a fortnight
up to 4 years. Further, we calculate summed magnitudes and depths and
counts of significant quakes (magnitude &amp;gt; 3.29). Other easily available
quantities are powers of quake energy (using Energy ~ 101.5m where m is
magnitude). Quantities are &amp;ldquo;Energy averaged&amp;rdquo; when there are multiple
events in a single space-time bin except for simple event counts.&lt;/p&gt;
&lt;p&gt;Current reference models are a basic LSTM recurrent neural network and a
modification of the original science transformer. Details can be found
&lt;a href=&#34;https://docs.google.com/presentation/d/1ykYnX0uvxPE-M-c-Tau8irU3IqYuvj8Ws8iUqd5RCxQ/edit?usp=sharing&#34;&gt;here&lt;/a&gt;,
and
&lt;a href=&#34;https://www.researchgate.net/publication/346012611_DRAFT_Deep_Learning_for_Spatial_Time_Series&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id=&#34;tevolop-specific-benchmark-targets&#34;&gt;TEvolOp Specific Benchmark Targets&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Scientific objective(s):
&lt;ul&gt;
&lt;li&gt;Objective: Improve the quality of Earthquake forecasting&lt;/li&gt;
&lt;li&gt;Formula: Normalized Nash&amp;ndash;Sutcliffe model efficiency coefficient
(NNSE)&lt;/li&gt;
&lt;li&gt;Score: The NNSE lies between 0.8 and 0.99 depending on model and
predicted time series&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data
&lt;ul&gt;
&lt;li&gt;Download:
&lt;a href=&#34;https://drive.google.com/drive/folders/1wz7K2R4gc78fXLNZMHcaSVfQvIpIhNPi?usp=sharing&#34;&gt;https://drive.google.com/drive/folders/1wz7K2R4gc78fXLNZMHcaSVfQvIpIhNPi?usp=sharing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Data Size: 5GB from USGS&lt;/li&gt;
&lt;li&gt;Training samples: Data is decided spatially in an 80%-20%
fashion between training and validation. The full dataset covers
6 degrees of longitude (-114 to -120) and 4 degrees of latitude
(32 to 56) In Southern California. This is divided into 2400
spatial bins 0.1 degree (~11km) on a side&lt;/li&gt;
&lt;li&gt;Validation samples: Most analyses use 500 most active bins of
which 400 are training and 100 validation.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Example implementation
&lt;ul&gt;
&lt;li&gt;Model: 3 state of the art geospatial deep learning
implementations are provided&lt;/li&gt;
&lt;li&gt;Reference Code:
&lt;a href=&#34;https://colab.research.google.com/drive/1JrPcRwX06xIN5iLhc53_MOLzU9q_Q7wD?usp=sharing&#34;&gt;https://colab.research.google.com/drive/1JrPcRwX06xIN5iLhc53_MOLzU9q_Q7wD?usp=sharing&lt;/a&gt;
(Second model below)&lt;/li&gt;
&lt;li&gt;Run Instructions: This is set up currently as a Jupyter notebook
to run on Colab/GitHub. A container DGX version is also
available&lt;/li&gt;
&lt;li&gt;Time-to-solution: 1 to 2 days on a single GPU&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;example-implementation&#34;&gt;Example Implementation:&lt;/h2&gt;
&lt;p&gt;The example implementation is primarily to demonstrate feasibility, show
how the data is represented, help address any interpretation
considerations, and potentially trigger initial ideas on how the
benchmark can be improved.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: STEMDL (Classification)</title>
      <link>/mlcommons/docs/benchmarks/stemdl/</link>
      <pubDate>Thu, 05 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/mlcommons/docs/benchmarks/stemdl/</guid>
      <description>
        
        
        

&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;p&gt;State of the art scanning transmission electron microscopes (STEM)
produce focused electron beams with atomic dimensions and allow to
capture diffraction patterns arising from the interaction of incident
electrons with nanoscale material volumes.&lt;/p&gt;

&lt;/div&gt;

&lt;h3 id=&#34;stemdl-classification&#34;&gt;STEMDL (Classification)&lt;/h3&gt;
&lt;p&gt;State of the art scanning transmission electron microscopes (STEM)
produce focused electron beams with atomic dimensions and allow to
capture diffraction patterns arising from the interaction of incident
electrons with nanoscale material volumes. Backing out the local atomic
structure of said materials requires compute- and time-intensive
analyses of these diffraction patterns (known as convergent beam
electron diffraction, CBED). Traditional analyses of CBED requires
iterative numerical solutions of partial differential equations and
comparison with experimental data to refine the starting material
configuration. This process is repeated anew for every newly acquired
experimental CBED pattern and/or probed material.&lt;/p&gt;
&lt;p&gt;In this &lt;a href=&#34;https://github.com/at-aaims/stemdl-benchmark&#34;&gt;benchmark&lt;/a&gt;, we
used newly developed multi-GPU and multi-node electron scattering
simulation codes &lt;a href=&#34;https://www.osti.gov/biblio/1631694-namsa&#34;&gt;[1]&lt;/a&gt; on
the Summit supercomputer to generate CBED patterns from over 60,000
materials (solid-state materials), representing nearly every known
crystal structure. A scaled-down version of this data
&lt;a href=&#34;https://doi.ccs.ornl.gov/ui/doi/70&#34;&gt;[2]&lt;/a&gt; is used for one of the data
challenges &lt;a href=&#34;https://smc-datachallenge.ornl.gov/challenge-2-2020/&#34;&gt;[3]&lt;/a&gt;
at SMC 2020 conference, and the overarching goals are to: (1) explore
the suitability of machine learning algorithms in the advanced analysis
of CBED and (2) produce a machine learning algorithm capable of
overcoming intrinsic difficulties posed by scientific datasets.&lt;/p&gt;
&lt;p&gt;A &lt;a href=&#34;https://doi.ccs.ornl.gov/ui/doi/70&#34;&gt;data&lt;/a&gt; sample from this data set
is given by a 3-d array formed by stacking various CBED patterns
simulated from the same material at different distinct material
projections (i.e. crystallographic orientations). Each CBED pattern is a
2-d array with float 32-bit image intensities. Associated with each data
sample in the data set is a host of material attributes or properties
which are, in principle, retrievable via analysis of this CBED stack. Of
note are (1) 200 crystal space groups out of 230 unique mathematical
discrete space groups and (2) local electron density which governs
material&amp;rsquo;s property.&lt;/p&gt;
&lt;p&gt;This benchmark consists of 2 tasks: classification for crystal space
groups and reconstruction for local electron density, the example
implementation of which are provided in
&lt;a href=&#34;https://link.springer.com/chapter/10.1007%2F978-3-030-63393-6_30&#34;&gt;[4]&lt;/a&gt;
and &lt;a href=&#34;https://arxiv.org/abs/1909.11150&#34;&gt;[5]&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id=&#34;stemdl-specific-benchmark-targets&#34;&gt;STEMDL Specific Benchmark Targets&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Scientific objective(s):
&lt;ul&gt;
&lt;li&gt;Objective: Classification for crystal space groups&lt;/li&gt;
&lt;li&gt;Formula: F1 score on validation data&lt;/li&gt;
&lt;li&gt;Score: 0.9 considered converged&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data
&lt;ul&gt;
&lt;li&gt;Download: &lt;a href=&#34;https://doi.ccs.ornl.gov/ui/doi/70&#34;&gt;https://doi.ccs.ornl.gov/ui/doi/70&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Data Size: 548.7 GiB&lt;/li&gt;
&lt;li&gt;Training samples: 138.7K&lt;/li&gt;
&lt;li&gt;Validation samples: 48.4&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Example implementation
&lt;ul&gt;
&lt;li&gt;Model: ResNet-50&lt;/li&gt;
&lt;li&gt;Reference Code: &lt;a href=&#34;https://github.com/at-aaims/stemdl-benchmark&#34;&gt;https://github.com/at-aaims/stemdl-benchmark&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Run Instructions:
&lt;a href=&#34;https://github.com/at-aaims/stemdl-benchmark#quickstart&#34;&gt;https://github.com/at-aaims/stemdl-benchmark#quickstart&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Time-to-solution: 40min on 60 V100 GPUs&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;

      </description>
    </item>
    
  </channel>
</rss>
