<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ML Science Benchmarks â€“ Tutorials</title>
    <link>/mlcommons/docs/tutorials/</link>
    <description>Recent content in Tutorials on ML Science Benchmarks</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Wed, 04 Jan 2017 00:00:00 +0000</lastBuildDate>
    
	  <atom:link href="/mlcommons/docs/tutorials/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Docs: Setting up Environment from Scratch</title>
      <link>/mlcommons/docs/tutorials/python-from-source/</link>
      <pubDate>Mon, 21 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>/mlcommons/docs/tutorials/python-from-source/</guid>
      <description>
        
        
        

&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;p&gt;A description on how to install nvcc in cuda&lt;/p&gt;

&lt;/div&gt;



&lt;div class=&#34;alert alert-warning&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Requirements&lt;/h4&gt;

    Draft

&lt;/div&gt;

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Most modern linux systems come prepackaged with a version of Python 3.
However, this version is typically deeply integrated into the operating system&amp;rsquo;s ecosystem of tools, so it may be a significantly older version of python and it may lack some optimizations to maximize compatibility.&lt;/p&gt;
&lt;p&gt;For benchmarking, it is desireable to have control over your source program, so that running programs are both consistent and repeatable.
Below are the steps to build Python 3.10.2 on a variety of hosts.&lt;/p&gt;
&lt;h2 id=&#34;setup&#34;&gt;Setup&lt;/h2&gt;
&lt;h3 id=&#34;configurations&#34;&gt;Configurations&lt;/h3&gt;
&lt;p&gt;This procedure assumes the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;You are building using &lt;code&gt;bash&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;You have &lt;code&gt;curl&lt;/code&gt;, &lt;code&gt;make&lt;/code&gt;, &lt;code&gt;gcc&lt;/code&gt;, &lt;code&gt;openssl&lt;/code&gt;, &lt;code&gt;bzip2&lt;/code&gt;, &lt;code&gt;libffi&lt;/code&gt;, &amp;lsquo;&lt;code&gt;zlib&lt;/code&gt;, &lt;code&gt;readline&lt;/code&gt;, &lt;code&gt;sqlite3&lt;/code&gt;, &lt;code&gt;llvm&lt;/code&gt;, &lt;code&gt;ncurses&lt;/code&gt;, and &lt;code&gt;xz&lt;/code&gt; c header files installed.&lt;/li&gt;
&lt;li&gt;You have set the following environment variables
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;BASE&lt;/code&gt; - Specifies the working directory for all operations.  This procedure assumes &lt;code&gt;~/.local&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;PREFIX&lt;/code&gt; - Where you want the final python instance to be positioned.  This procedure assumes &lt;code&gt;${BASE}/python/3.10.2&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;build-openssl&#34;&gt;Build OpenSSL&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Fetch source code&lt;/span&gt;
curl -OL https://www.openssl.org/source/openssl-1.1.1m.tar.gz
tar -zxvf openssl-1.1.1m.tar.gz -C &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;BASE&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;/src/
&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;BASE&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;/src/openssl-1.1.1m/
./config --prefix&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;BASE&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;/ssl --openssldir&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;BASE&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;/ssl shared zlib
make
&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;#make test&lt;/span&gt;
make instal
make clean
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;build-python&#34;&gt;Build Python&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl -OL https://www.python.org/ftp/python/3.10.2/Python-3.10.2.tar.xz
tar Jxvf Python-3.10.2.tar.xz -C &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;BASE&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;/src/
&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; Python-3.10.2
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;CPPFLAGS&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34; -I&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;BASE&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;/ssl/include &amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;LDFLAGS&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34; -L&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;BASE&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;/ssl/lib &amp;#34;&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;LD_LIBRARY_PATH&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;BASE&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;/ssl/lib:&lt;span style=&#34;color:#000&#34;&gt;$LD_LIBRARY_PATH&lt;/span&gt;
./configure --prefix&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;PREFIX&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; --enable-optimizations --with-lto --with-computed-gotos --with-system-ffi

make -j &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;nproc&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&lt;/span&gt;
make &lt;span style=&#34;color:#204a87&#34;&gt;test&lt;/span&gt;
make altinstall
make clean

mkdir -p &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;BASE&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;/.local/bin
&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;BASE&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;/bin &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;;&lt;/span&gt; ln -s python3.10 python&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;

cat &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;lt;&amp;lt;EOF &amp;gt; ${BASE}/setup.source
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;#!/bin/bash
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;BASE=$BASE
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;PREFIX=$PREFIX
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;export LD_LIBRARY_PATH=\$BASE/ssl/lib:\$PREFIX/lib:\$LD_LIBRARY_PATH
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;export PATH=\$PREFIX/bin:\$PATH
&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;EOF&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;archive-build&#34;&gt;Archive Build&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;tar Jxvf python-3.10.2.tar .xz &lt;span style=&#34;color:#000&#34;&gt;$BASE&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;common-setup-procedures&#34;&gt;Common Setup Procedures&lt;/h2&gt;
&lt;p&gt;To bootstrap your new environment with all the tools frequently leveraged during development, see the below procedures.&lt;/p&gt;
&lt;p&gt;Assumption: The variable &lt;code&gt;BASE&lt;/code&gt; is your user home directory, and python3.10 is on the path.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;mkdir -p &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;BASE&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;/ENV3
python3.10 -m venv --prompt ENV3 ~/ENV3

&lt;span style=&#34;color:#204a87&#34;&gt;source&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;BASE&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;/ENV3/bin/activate
pip install -U pip
pip install cloudmesh-installer

mkdir -p ~/git/cm
&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; ~/git/cm &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; cloudmesh-installer get cms&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;

&lt;span style=&#34;color:#204a87&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;alias ENV3=\&amp;#34;source &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$BASE&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;/ENV3/bin/activate\&amp;#34;&amp;#34;&lt;/span&gt; &amp;gt;&amp;gt; ~/.bash_profile
&lt;span style=&#34;color:#204a87&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;alias EQ=\&amp;#34;cd &lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;$BASE&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;/git\&amp;#34;&amp;#34;&lt;/span&gt; &amp;gt;&amp;gt; ~/.bash_profile
&lt;span style=&#34;color:#204a87&#34;&gt;source&lt;/span&gt; ~/.bash_profile

EQ

git clone git@github.com:laszewsk/mlcommons.git
git clone git@github.com:laszewsk/mlcommons-data-earthquake.git

pip install -r mlcommons/examples/mnist-tensorflow/requirements.txt
pip install -r mlcommons/benchmarks/earthquake/new/requirements.txt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
      </description>
    </item>
    
    <item>
      <title>Docs: Running MLCube on Rivanna</title>
      <link>/mlcommons/docs/tutorials/introduction-to-mlcube/</link>
      <pubDate>Sun, 06 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>/mlcommons/docs/tutorials/introduction-to-mlcube/</guid>
      <description>
        
        
        

&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;p&gt;In this guide, we introduce MLCube and demonstrate how to run
workloads on Rivanna using the Singularity backend.&lt;/p&gt;

&lt;/div&gt;

&lt;p&gt;Running models consistently across platforms requires users to have
commanding knowledge of the configuration of not only the source code,
but also of the hardware ecosystem.  It&amp;rsquo;s not uncommon that you&amp;rsquo;ll
encounter a project where configuring your system to get reproducible
results is error prone and time consuming, and ultimately not
productive to the analyst.&lt;/p&gt;
&lt;p&gt;MLCube(tm) is a contract-driven approach to address system
configuration details and establishes a standard for generating
consistent models and a mechanism for delivering these models to
others, allowing others to benefit from having a solved environment.&lt;/p&gt;
&lt;h2 id=&#34;getting-started&#34;&gt;Getting Started&lt;/h2&gt;
&lt;p&gt;First you need to install a runner for MLCube.  The MLCube supports
many backend runners and should run on each of them equally.&lt;/p&gt;
&lt;p&gt;For this walkthrough, we will target the Rivanna HPC ecosystem, so
we&amp;rsquo;ll leverage the lmod and singularity ecosystems.&lt;/p&gt;
&lt;h2 id=&#34;python-install&#34;&gt;Python install&lt;/h2&gt;
&lt;p&gt;We have two
choices to install python. One is with pyenv, the other is with conda.&lt;/p&gt;
&lt;p&gt;If you decide to install it with pyenv, use the following steps&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;pyenv install 3.9.7
pyenv global 3.9.7
python -m venv --prompt mlcube venv
&lt;span style=&#34;color:#204a87&#34;&gt;source&lt;/span&gt; venv/bin/activate
python -m pip install mlcube-singularity
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If you decide to install it with conda, use the following steps&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;conda create -n mlcube -c conda-forge python=3.9.7
conda activate mlcube
# We use pip as conda does not have an mlcube repository
python -m pip install mlcube-singularity
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Note that the &lt;code&gt;mlcube-singularity&lt;/code&gt; package can and should be installed
within your target environment.&lt;/p&gt;
&lt;h2 id=&#34;using-mlcube&#34;&gt;Using MLCube&lt;/h2&gt;
&lt;p&gt;Once you have run the above commands, you will now have the MLCube
script available on your path and you can now list what runners mlcube
has registered with&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ mlcube config --get runners
&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# System settings file path = /home/&amp;lt;username&amp;gt;/mlcube.yaml&lt;/span&gt;
&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# singularity:&lt;/span&gt;
&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;#   pkg: mlcube_singularity&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;At this point you can run through any of the example projects that the
mlcube project hosts at
&lt;a href=&#34;https://github.com/mlcommons/mlcube_examples.git&#34;&gt;https://github.com/mlcommons/mlcube_examples.git&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Below is a set of procedures to run their hello world project.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;git clone https://github.com/mlcommons/mlcube_examples.git
&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; ./mlcube_examples/hello_world

mlcube run --mlcube&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;. --task&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;hello --platform&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;singularity
&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# No output expected.&lt;/span&gt;

mlcube run --mlcube&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;. --task&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;bye --platform&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;singularity
&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# No output expected.&lt;/span&gt;

cat ./workspace/chats/chat_with_alice.txt
&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# You should some log lines in this file.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;nontrivial-example---earthquake-data&#34;&gt;Nontrivial example - Earthquake Data&lt;/h2&gt;


&lt;div class=&#34;alert alert-information&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Help wanted&lt;/h4&gt;

    We are looking to convert our earthquake model into an MLCube container.

&lt;/div&gt;


      </description>
    </item>
    
    <item>
      <title>Docs: Singularity Collection</title>
      <link>/mlcommons/docs/tutorials/singularity/</link>
      <pubDate>Sun, 06 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>/mlcommons/docs/tutorials/singularity/</guid>
      <description>
        
        
        

&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;p&gt;A collection of information about Singularity&lt;/p&gt;

&lt;/div&gt;

&lt;h2 id=&#34;user-guides&#34;&gt;User Guides&lt;/h2&gt;
&lt;p&gt;Add gregors info&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://sylabs.io/guides/2.6/user-guide/index.html&#34;&gt;User Manual&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://frontera-portal.tacc.utexas.edu/user-guide/containers/&#34;&gt;Frontera&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://frontera-portal.tacc.utexas.edu/user-guide/docs/containers-at-tacc.pdf&#34;&gt;TACC&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;presentations&#34;&gt;Presentations&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.sdsc.edu/Events/training/singularity_on_comet_2019/introduction-to-singularity.pdf&#34;&gt;SDSC Singularity Tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.nersc.gov/assets/GPUs-for-Science-Day/shane-cannon.pdf&#34;&gt;NERSC ubuntu14.04 ;-)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.chpc.utah.edu/presentations/images-and-pdfs/Containers17.pdf&#34;&gt;Utah&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;organize&#34;&gt;Organize&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://tacc.github.io/pearc19-hpc-in-the-cloud/block3/intro-singularity/&#34;&gt;TACC Singularity&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;containers&#34;&gt;Containers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://portal.xsede.org/containers&#34;&gt;XSEDE Containers&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://slurm.schedmd.com/containers.html&#34;&gt;Slurm&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.turing.ac.uk/research/asg/pearl&#34;&gt;Pearl&lt;/a&gt; (2^ &lt;a href=&#34;https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/dgx-1/dgx-2-datasheet-us-nvidia-955420-r2-web-new.pdf&#34;&gt;DGX2&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.rc.virginia.edu/userinfo/rivanna/software/containers/&#34;&gt;Rivanna&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Installing Singularity on Windows Workstations</title>
      <link>/mlcommons/docs/tutorials/introduction-to-singularity/</link>
      <pubDate>Sun, 06 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>/mlcommons/docs/tutorials/introduction-to-singularity/</guid>
      <description>
        
        
        &lt;p&gt;Singularity is a container-based runtime engine designed to run in permission constrained environments.
Singularity provides similar functions to systems like Docker, Containerd, and Podman, and provides an ecosystem to share a computer&amp;rsquo;s kernel and drivers and provide a filesystem based on overlaying files.
These overlays create a type of partitioned software that that can create isolated execution on the host as a type of &amp;ldquo;container&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;However, Singularity differs from typical container runtime engine, most notably:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Singularity was designed to be run as a normal, non-root user and does not depend on a daemon.&lt;/li&gt;
&lt;li&gt;Singularity does not natively support OCI images (the typical container image format target), and uses its own SIF format; but OCI images can be imported.&lt;/li&gt;
&lt;li&gt;Singularity container images are distributed as files.&lt;/li&gt;
&lt;li&gt;Singularity was designed to create a container platform that works from laptops to HPC clusters.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;windows-only-setup-on-window-subsystem-for-linux&#34;&gt;(Windows Only) Setup on Window Subsystem for Linux&lt;/h2&gt;
&lt;p&gt;While not the normal place to install singularity, it is useful to have the ability to run commands from a local machine to validate command structure and workflows.
Singularity does not run natively on windows, but with Windows 10 Professional, you can build Singularity using a WSL2 distribution and provide the ability to run the commands on your workstation.&lt;/p&gt;
&lt;h3 id=&#34;enabling-wsl2&#34;&gt;Enabling WSL2&lt;/h3&gt;
&lt;p&gt;To enable WSL2, follow microsoft&amp;rsquo;s instructions&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Windows 10/11 - &lt;a href=&#34;https://docs.microsoft.com/en-us/windows/wsl/install&#34;&gt;https://docs.microsoft.com/en-us/windows/wsl/install&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Windows 10 older than 2004 - &lt;a href=&#34;https://docs.microsoft.com/en-us/windows/wsl/install-manual&#34;&gt;https://docs.microsoft.com/en-us/windows/wsl/install-manual&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Any version of linux will work with Singularity, but we recommend using Ubuntu.&lt;/p&gt;
&lt;h2 id=&#34;building-singularity&#34;&gt;Building Singularity&lt;/h2&gt;
&lt;p&gt;This process has been automated in &lt;code&gt;./tools/install-singularity-wsl2.bash&lt;/code&gt; if you&amp;rsquo;re running Ubuntu.
However, the general flow of the instruction is:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Install the singularity code dependencies (gcc, libssl, gpgme, squashfs, seccomp, wget, pkg-config, git, and cryptsetup)&lt;/li&gt;
&lt;li&gt;Install a modern version of golang.&lt;/li&gt;
&lt;li&gt;Download the Singularity source code from &lt;a href=&#34;https://github.com/apptainer/singularity.git&#34;&gt;https://github.com/apptainer/singularity.git&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Run &lt;code&gt;./mconfig&lt;/code&gt; from the singularity codebase&lt;/li&gt;
&lt;li&gt;Run &lt;code&gt;make &amp;amp;&amp;amp; make install&lt;/code&gt; from the &lt;code&gt;./builddir&lt;/code&gt; directory.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These procedures are more thoroughly covered in the apptainer website at: &lt;a href=&#34;https://apptainer.org/docs/user/main/quick_start.html#quick-installation-steps&#34;&gt;https://apptainer.org/docs/user/main/quick_start.html#quick-installation-steps&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;run-your-first-singularity-container&#34;&gt;Run your first singularity container&lt;/h3&gt;
&lt;p&gt;Once the build has completed, you should be able to run the &lt;code&gt;singularity&lt;/code&gt; command.
Try to run&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ singularity run docker://godlovedc/lolcow
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If this command was successful you should see something similar to the following:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt; _____________________________________
/ You recoil from the crude; you tend \
\ naturally toward the exquisite.     /
 -------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
      </description>
    </item>
    
    <item>
      <title>Docs: Running GPU Batch jobs on Rivanna</title>
      <link>/mlcommons/docs/tutorials/rivanna/</link>
      <pubDate>Thu, 05 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/mlcommons/docs/tutorials/rivanna/</guid>
      <description>
        
        
        

&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;p&gt;We explain how to run GPU batch jobs using different GPU cards on
Rivanna. Rivanna is a supercomputer at the University of Virginia. This
tutorial is only useful if you can get an account on it. The
official documentation is available at&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.rc.virginia.edu/userinfo/rivanna/overview/&#34;&gt;https://www.rc.virginia.edu/userinfo/rivanna/overview/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;However, it includes some issues and does not explain certain
important aspects for using GPUs on it. Therefore, this guide has been
created.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;PLEASE HELP US IMPROVE THIS GUIDE&lt;/strong&gt;&lt;/p&gt;

&lt;/div&gt;



&lt;div class=&#34;alert alert-warning&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Requirements&lt;/h4&gt;

    &lt;p&gt;We require that you have&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A valid account on Rivanna&lt;/li&gt;
&lt;li&gt;A valid accounting group allowing you to run GPU jobs on Rivanna&lt;/li&gt;
&lt;/ul&gt;


&lt;/div&gt;

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Rivanna is the High-Performance Computing (HPC) cluster
managed by University of Virginia&amp;rsquo;s Research Computing. Rivanna is
composed 575 nodes with a total of 20,476 cores and 8PB of different
types of storage. Table 1 shows an overview of the compute
nodes. Some of the compute nodes also includes these GPUs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.nvidia.com/en-us/data-center/a100/&#34;&gt;A100&lt;/a&gt;,
&lt;a href=&#34;https://www.nvidia.com/en-gb/data-center/tesla-k80/&#34;&gt;K80&lt;/a&gt;,
&lt;a href=&#34;https://www.nvidia.com/en-us/data-center/tesla-p100/&#34;&gt;P100&lt;/a&gt;,
&lt;a href=&#34;https://www.nvidia.com/en-us/data-center/v100/&#34;&gt;V100&lt;/a&gt;,
&lt;a href=&#34;https://www.nvidia.com/en-us/geforce/20-series/&#34;&gt;RTX2080&lt;/a&gt;,
and
&lt;a href=&#34;https://www.nvidia.com/en-us/geforce/graphics-cards/30-series/rtx-3090/&#34;&gt;RTX3090&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Table 1:&lt;/strong&gt; GPUs on Rivanna&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Cores/Node&lt;/th&gt;
&lt;th&gt;Memory/Node&lt;/th&gt;
&lt;th&gt;Specialty Hardware&lt;/th&gt;
&lt;th&gt;GPU memory/Device&lt;/th&gt;
&lt;th&gt;GPU devices/Node&lt;/th&gt;
&lt;th&gt;# of Nodes&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;40&lt;/td&gt;
&lt;td&gt;354GB&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;20&lt;/td&gt;
&lt;td&gt;127GB&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;115&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;28&lt;/td&gt;
&lt;td&gt;255GB&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;25&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;40&lt;/td&gt;
&lt;td&gt;768GB&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;34&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;40&lt;/td&gt;
&lt;td&gt;384GB&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;348&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;24&lt;/td&gt;
&lt;td&gt;550GB&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;16&lt;/td&gt;
&lt;td&gt;1000GB&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;48&lt;/td&gt;
&lt;td&gt;1500GB&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;64&lt;/td&gt;
&lt;td&gt;180GB&lt;/td&gt;
&lt;td&gt;KNL&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;128&lt;/td&gt;
&lt;td&gt;1000GB&lt;/td&gt;
&lt;td&gt;GPU: A100&lt;/td&gt;
&lt;td&gt;40GB&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;28&lt;/td&gt;
&lt;td&gt;255GB&lt;/td&gt;
&lt;td&gt;GPU: K80&lt;/td&gt;
&lt;td&gt;11GB&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;28&lt;/td&gt;
&lt;td&gt;255GB&lt;/td&gt;
&lt;td&gt;GPU: P100&lt;/td&gt;
&lt;td&gt;12GB&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;40&lt;/td&gt;
&lt;td&gt;383GB&lt;/td&gt;
&lt;td&gt;GPU: RTX 2080 Ti&lt;/td&gt;
&lt;td&gt;11GB&lt;/td&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;28&lt;/td&gt;
&lt;td&gt;188GB&lt;/td&gt;
&lt;td&gt;GPU: V100&lt;/td&gt;
&lt;td&gt;16GB&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;40&lt;/td&gt;
&lt;td&gt;384GB&lt;/td&gt;
&lt;td&gt;GPU: V100&lt;/td&gt;
&lt;td&gt;32GB&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;*) This information may be outdated&lt;/p&gt;
&lt;h2 id=&#34;access-to-rivanna&#34;&gt;Access to Rivanna&lt;/h2&gt;
&lt;p&gt;Access to Rivanna is secured by &lt;a href=&#34;https://virginia.service-now.com/its/?id=itsweb_kb_article&amp;amp;sys_id=f24e5cdfdb3acb804f32fb671d9619d0&#34;&gt;University of Virginias
VPN&lt;/a&gt;. UVA
offers two different VPNs. We recommend that you install the &lt;strong&gt;UVA
Anywhere VPN&lt;/strong&gt;. This can be installed on Linux, macOS and Windows.&lt;/p&gt;
&lt;p&gt;After installation, you have to start the VPN. After that, you can use a
terminal to access Rivanna via ssh. If you have not used ssh, we
encourage you to read about it and explore commands such as &lt;code&gt;ssh&lt;/code&gt;,
&lt;code&gt;ssh-keygen&lt;/code&gt;, &lt;code&gt;ssh-copy-id&lt;/code&gt;, &lt;code&gt;ssh-agent, and &lt;/code&gt;ssh-add`.&lt;/p&gt;


&lt;div class=&#34;alert alert-warning&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Note: gitbash on Windows&lt;/h4&gt;

    Please note that on Windows, you are expected to install gitbash so
you can use the same commands and ssh logic as on Linux and Mac. For
this reason, we do not recommend &lt;code&gt;putty&lt;/code&gt;, &lt;code&gt;PowerShell&lt;/code&gt; or
&lt;code&gt;cmd.exe&lt;/code&gt;. This is because we can do scripting the same way, even from
those running Windows, and significantly simplifies this guide.

&lt;/div&gt;

&lt;p&gt;We will not provide an extensive tutorial on how to use
ssh, but you can contribute it. Instead, we will summarize the most important steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create an ssh key if you have not done that before&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ ssh-keygen
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;It is &lt;strong&gt;VERY&lt;/strong&gt; important that you create the key with a strong passphrase.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Add an abbreviation for Rivanna to your &lt;code&gt;~/.ssh/config&lt;/code&gt; file&lt;/p&gt;
&lt;p&gt;Use your favorite editor. Mine is &lt;code&gt;emacs&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;emacs ~/.ssh/config&lt;/p&gt;
&lt;p&gt;copy and paste the following into that file, where &lt;code&gt;abc1de&lt;/code&gt; is to be substituted by your
UVA compute id.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;Host rivanna
  User abc1de
  HostName rivanna.hpc.virginia.edu 
  IdentityFile ~/.ssh/id_rsa.pub
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This will allow you to use &lt;code&gt;rivanna&lt;/code&gt; instead of &lt;code&gt;abc1de@rivanna.hpc.virginia.edu&lt;/code&gt;.
The next steps assume you have done this and can use just &lt;code&gt;rivanna&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Copy your public key to rivanna&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ ssh-copy-id rivanna
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This will copy your public key into the
&lt;code&gt;rivanna:~/.ssh/authorized_keys&lt;/code&gt; file.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;After this step, you can use your keys to authenticate. You still
need to be using the VPN, though.&lt;/p&gt;
&lt;p&gt;The most convenient system for it is Mac and Ubuntu. It
already has a tool installed called ssh-agent and keychain. In
Windows under gitbash you need to start it with&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ &lt;span style=&#34;color:#204a87&#34;&gt;eval&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;`&lt;/span&gt;ssh-agent&lt;span style=&#34;color:#4e9a06&#34;&gt;`&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;First, you add the key to your session, so you do not have to
constantly type in the password. Use the command&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ ssh-add
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;to test if it works, just say&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ ssh rivanna hostanme
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;which will print the hostname of Rivanna&lt;/p&gt;
&lt;p&gt;In case your machine does not run ssh-agent, you can start it
before you type in the ssh-add command with&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ ssh rivanna hostanme
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If everything is set up correctly, it will return  the string&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;udc-ba35-36
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;To login to Rivanna, simply say&lt;/p&gt;
&lt;p&gt;&amp;ldquo;`bash
ssh rivanna&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;
If this does not work, you have made a mistake. Please, review the
previous steps carefully.

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;running-jobs-on-rivanna&#34;&gt;Running Jobs on Rivanna&lt;/h2&gt;
&lt;p&gt;Jobs on Rivanna can be scheduled through Slurm either as a batch job or
as an interactive job. In order to achieve this, one needs to load the
software first and create special scripts that are used to submit them
to nodes that contain the GPUs you specify.&lt;/p&gt;
&lt;p&gt;The user documentation about this is provided here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.rc.virginia.edu/userinfo/rivanna/overview/#gpu-partition&#34;&gt;https://www.rc.virginia.edu/userinfo/rivanna/overview/#gpu-partition&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;However, at the time when we looked at it, it had some mistakes and
limitations that we hope to overcome here.&lt;/p&gt;
&lt;h3 id=&#34;modules&#34;&gt;Modules&lt;/h3&gt;
&lt;p&gt;Rivanna&amp;rsquo;s default mechanism of software configuration management is
done via
&lt;a href=&#34;https://lmod.readthedocs.io/en/latest/index.html&#34;&gt;modules&lt;/a&gt;. The UVA
modules documentation is provided through this
&lt;a href=&#34;https://www.rc.virginia.edu/userinfo/rivanna/software/modules/&#34;&gt;link&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Modules provide the ability to load a particular software stack and
configuration into your shell but also into your batch jobs. You can
load multiple modules in your environment to load them in order.&lt;/p&gt;
&lt;p&gt;To list the available modules, log into Rivanna and use the command&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;$ module available
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To list aproximately, the python modules use&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;$ module available py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;It will return all modules that have py in it. Please chose those that
look like python modules.&lt;/p&gt;
&lt;p&gt;To probe for deep learning modules, use  something similar to&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;$ module available cuda tensorflow pytorch mxnet nvidia cudnn
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;python&#34;&gt;Python&lt;/h3&gt;
&lt;p&gt;Different versions of python are available.&lt;/p&gt;
&lt;p&gt;To load python 3.8 we can say&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ module load anaconda/2020.11-py3.8
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To load Python 3.10.0 we can say&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;$ module load anaconda
$ conda create -n py3.10 python=3.10
$ source activate py3.10
$ python -V
Python 3.10.0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Please note that at this time anaconda did not support 3.10.2, which I
run personally on my computer, but from python.org.&lt;/p&gt;
&lt;h3 id=&#34;adding-modules-with-spider&#34;&gt;Adding Modules with Spider&lt;/h3&gt;
&lt;p&gt;Details about modules can be identified with the &lt;code&gt;module spider&lt;/code&gt; command.
If you type it in you get a list of many available configurations.
Spider can take a keyword and lists all available version the keyword matches.
Let us demonstrate it on&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ module spider python
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;----------------------------------------------------------------------------
  python:
----------------------------------------------------------------------------
    Description:
      Python is a programming language that lets you work more effectively.

     Versions:
        python/2.7.16
        python/3.6.6
        python/3.6.8
        python/3.7.7
        python/3.8.8
     Other possible modules matches:
        biopython  openslide-python  wxpython
----------------------------------------------------------------------------
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For detailed information about a specific &amp;ldquo;python&amp;rdquo; package use the module&amp;rsquo;s full name.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ module spider python/3.8.8
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This will return a page with lots of information. The most important one for us is&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt; You will need to load all module(s) on any one of the lines below before the
 &amp;#34;python/3.8.8&amp;#34; module is available to load.

      gcc/11.2.0  openmpi/3.1.6
      gcc/9.2.0  cuda/11.0.228  openmpi/3.1.6
      gcc/9.2.0  mvapich2/2.3.3
      gcc/9.2.0  openmpi/3.1.6
      gcccuda/9.2.0_11.0.228  openmpi/3.1.6
      goolfc/9.2.0_3.1.6_11.0.228
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Here you see various options that need to be loaded in &lt;strong&gt;BEFORE&lt;/strong&gt; you load python.&lt;/p&gt;
&lt;p&gt;Thus to properly load python 3.8.8 you need to say (if this is what you chose):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;module load gcc/11.2.0
module load openmpi/3.1.6
module spider python/3.8.8
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;modules-for-tensorflow&#34;&gt;Modules for tensorflow&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;module load singularity/3.7.1
module load tensorflow/2.7.0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;modules-for-pytorch&#34;&gt;Modules for pytorch&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;module load singularity/3.7.1
module lod pytorch/1.10.0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;containers&#34;&gt;Containers&lt;/h3&gt;
&lt;p&gt;Rivanna uses singularity as container technology. The documentation
specific to singularity for Rivanna is avalable at this
&lt;a href=&#34;https://www.rc.virginia.edu/userinfo/rivanna/software/containers/&#34;&gt;link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Singularity needs to be also loaded as a module befor it can be used.&lt;/p&gt;
&lt;p&gt;Singularity containers have the ability to access
&lt;a href=&#34;https://www.rc.virginia.edu/userinfo/rivanna/software/containers/#running-gpu-images&#34;&gt;GPUs&lt;/a&gt;
via a passthrough using NVidia drivers. Once you load singularity you
can use it as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;singularity &amp;lt;cmd&amp;gt; --nv &amp;lt;imagefile&amp;gt; &amp;lt;args&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The container will be used inside a job.&lt;/p&gt;
&lt;h3 id=&#34;jobs&#34;&gt;Jobs&lt;/h3&gt;
&lt;p&gt;More detail specific to jobs for Rivanna is provided
&lt;a href=&#34;https://www.rc.virginia.edu/userinfo/rivanna/slurm/#gpu-intensive-computation&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Before we start an example, we explain how we create a job first in a
job description file and then submit it to Rivanna. We use a simple
MNIST example showcases the aspects of successfully running a job on
the machine. We will therefore focus on creating jobs using GPUs.&lt;/p&gt;


&lt;div class=&#34;alert alert-warning&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;New 8  A100 GPUs to be added&lt;/h4&gt;

    &lt;p&gt;Rivanna will have eight nodes available to us, but they are not yet in service.&lt;/p&gt;
&lt;p&gt;Instead, we will be using the two existing nodes shared with other users.&lt;/p&gt;


&lt;/div&gt;

&lt;p&gt;Rivanna uses the SLURM job scheduler for allocating submitted jobs.
Jobs are charged SUs from an allocation. The Rivanna compute
allocation. Please contact your supervisor for the name of the allocation. Gregor&amp;rsquo;s allocation is named&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;bii_dsc&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;and it currently contains 100k SUs.  Students from the UVA capstone
class will have the following allocation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ds6011-sp22-002&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To see the available SUs for your project, please use the command&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;allocations&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;allocations -a &amp;lt;allocation_name&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;SUs can be requested via the &lt;a href=&#34;https://www.rc.virginia.edu/userinfo/rivanna/allocations/&#34;&gt;Standard Allocation Renewal
form&lt;/a&gt;. Due
to the limitation, we encourage you to plan things and try to
avoid unnecessary runs. General instructions for submitting SLURM jobs
is located at&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.rc.virginia.edu/userinfo/rivanna/slurm/&#34;&gt;https://www.rc.virginia.edu/userinfo/rivanna/slurm/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To request the job be submitted to the GPU partition, you use the option&lt;/p&gt;
&lt;p&gt;&lt;code&gt;-p gpu&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The A100 GPUs are a requestable resource. To request them, you would
add the gres option with the number of A100 GPUs requested (1 through
8 GPUs), for example, to request 2 A100 GPUs,&lt;/p&gt;
&lt;p&gt;&lt;code&gt;--gres=gpu:a100:2&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;If you are using a SLURM script to submit the job the options
would appear as follows. Your script will need to specify other
options such as the allocation to charge as seen in the sample scripts
shown in the above URL:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;#SBATCH -p gpu
#SBATCH --gres=gpu:a100:2
#SBATCH -A bii_dsc
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;interactive-jobs&#34;&gt;Interactive Jobs&lt;/h3&gt;
&lt;p&gt;Please avoid running interactive jobs as they may waste
SUs, and we are charged by you keeping the A100 idle.&lt;/p&gt;
&lt;p&gt;Although Research Computing also offers some interactive apps such as
JupyterLab, RStudio, CodeServer, Blender, Mathematica via our Open
OnDemand portal at:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://rivanna-portal.hpc.virginia.edu&#34;&gt;https://rivanna-portal.hpc.virginia.edu&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;we ask you to avoid using them for benchmarks.&lt;/p&gt;
&lt;p&gt;To request the use of the A100s via Open OnDemand, first log in to the
Open the OnDemand portal select the desired interactive app. You will be
presented with a form to complete. Currently, you would&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;select &lt;code&gt;gpu&lt;/code&gt; for Rivanna partition,&lt;/li&gt;
&lt;li&gt;select &lt;code&gt;NVIDIA A100&lt;/code&gt; from the &lt;code&gt;Optional: GPU type for GPU partition&lt;/code&gt;
pulldown menu and enter the number of desired GPUs from the
&lt;code&gt;Optional: Number of GPUs&lt;/code&gt;. Once you&amp;rsquo;ve completed the form, click
the &lt;code&gt;Launch&lt;/code&gt; button and your session will be launched. The session
will start once the resources are available.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;using-the-mnist-example&#34;&gt;Using the MNIST example&lt;/h3&gt;
&lt;p&gt;For now, the code is located at:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/laszewsk/mlcommons/tree/main/examples/mnist-tensorflow&#34;&gt;https://github.com/laszewsk/mlcommons/tree/main/examples/mnist-tensorflow&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A sample slurm job specification is included at&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/laszewsk/mlcommons/blob/main/examples/mnist-tensorflow/mnist-rivanna-a100.slurm&#34;&gt;https://github.com/laszewsk/mlcommons/blob/main/examples/mnist-tensorflow/mnist-rivanna-a100.slurm&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To run it use the command&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ sbatch mnist-rivanna-a100.slurm
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;NOTE: We want to improve the script to make sure it is running on a
GPU and add GPU placement commands into the code.&lt;/p&gt;
&lt;h3 id=&#34;custom-version-of-tensorflow&#34;&gt;Custom Version of TensorFlow&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://www.rc.virginia.edu/userinfo/rivanna/software/tensorflow/&#34;&gt;https://www.rc.virginia.edu/userinfo/rivanna/software/tensorflow/&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;keras-on-rivanna&#34;&gt;Keras on Rivanna&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.rc.virginia.edu/userinfo/rivanna/software/keras/&#34;&gt;https://www.rc.virginia.edu/userinfo/rivanna/software/keras/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;building-a-python-verion-from-source&#34;&gt;Building a Python verion from Source&lt;/h2&gt;


&lt;div class=&#34;alert alert-warning&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Requirements&lt;/h4&gt;

    This section is under development

&lt;/div&gt;

&lt;h3 id=&#34;why-do-you-wnat-to-do-this&#34;&gt;Why do you wnat to do this?&lt;/h3&gt;
&lt;h3 id=&#34;how-is-it-been-done&#34;&gt;How is it been done?&lt;/h3&gt;
&lt;p&gt;Whe have developed the following script to create the enfironment on rivanna
\url{httplatex ://example.com}&lt;/p&gt;
&lt;p&gt;You can download the script from git with wget&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;wget ....
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;and place it in a driectory. running it with&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ python-install.py --version&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;3.10.2&amp;#34;&lt;/span&gt; --host&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;rivanna
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;will create an optimized version for rivanna. Other options can be found with
python-install.py help&lt;/p&gt;
&lt;h3 id=&#34;where-do-you-want-to-place-it&#34;&gt;Where do you want to place it&lt;/h3&gt;
&lt;p&gt;scratch vs home dir&lt;/p&gt;
&lt;h3 id=&#34;how-do-you-access-it&#34;&gt;How do you access it?&lt;/h3&gt;
&lt;p&gt;deployment into your own environment&lt;/p&gt;
&lt;h3 id=&#34;what-is-the-performance-gain&#34;&gt;What is the performance gain?&lt;/h3&gt;
&lt;p&gt;benchmarks vs the various versions on python here. This needs to be reproducible when we have a new version of python&lt;/p&gt;
&lt;h3 id=&#34;how-to-cite-if-you-use-this&#34;&gt;How to cite if you use this&lt;/h3&gt;
&lt;p&gt;This work was conducted as part of the mlcommons science benchmark earthquake project and if youl ike to reuse it we like that you cite the following paper:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;@TechReport{mlcommons-eartquake,
  author = 	 {Thomas Butler and Robert Knuuti and
              Jake Kolessar and Geoffrey C. Fox and
              Gregor von Laszewski and Judy Fox},
  title = 	 {MLCommons Earthquake Science Benchmark},
  institution =  {MLCommons Science Working Group},
  year = 	 2022,
  type = 	 {Report by University of Virginia},
  address = 	 {Charlottesville, VA},
  month = 	 may,
  note = 	 {The order of the authors and url location may change},
  annote = 	 {Version: draft},
  url = {https://github.com/cyberaide/paper-capstone-mlcommons}
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
      </description>
    </item>
    
    <item>
      <title>Docs: Installing nvcc on Uuntu 20.04</title>
      <link>/mlcommons/docs/tutorials/cuda/</link>
      <pubDate>Thu, 05 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/mlcommons/docs/tutorials/cuda/</guid>
      <description>
        
        
        

&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;p&gt;A description on how to install nvcc in cuda&lt;/p&gt;

&lt;/div&gt;



&lt;div class=&#34;alert alert-warning&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Requirements&lt;/h4&gt;

    Draft

&lt;/div&gt;

&lt;h2 id=&#34;instalation&#34;&gt;Instalation&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ sudo wget -O /etc/apt/preferences.d/cuda-repository-pin-600 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin
$ sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/7fa2af80.pub
$ sudo add-apt-repository &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;deb http://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/ /&amp;#34;&lt;/span&gt;
$ sudo apt update
$ sudo apt install cuda
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Add it to your path&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ &lt;span style=&#34;color:#204a87&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;export PATH=/usr/local/cuda/bin${PATH:+:${PATH}}&amp;#39;&lt;/span&gt; &amp;gt;&amp;gt; ~/.bashrc
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Check CUDA version:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ nvcc --version
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Wed_Oct_23_19:24:38_PDT_2019
Cuda compilation tools, release 10.2, V10.2.89
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
      </description>
    </item>
    
    <item>
      <title>Docs: Installing tensorflow on Windows 10</title>
      <link>/mlcommons/docs/tutorials/tensorflow-windows/</link>
      <pubDate>Thu, 05 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/mlcommons/docs/tutorials/tensorflow-windows/</guid>
      <description>
        
        
        

&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;p&gt;A description on how to install nvcc in cuda&lt;/p&gt;

&lt;/div&gt;



&lt;div class=&#34;alert alert-warning&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Requirements&lt;/h4&gt;

    Draft

&lt;/div&gt;

&lt;h2 id=&#34;instalation&#34;&gt;Instalation&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ TBD
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Add it to your path&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ TBD
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Check CUDA version:&lt;/p&gt;

      </description>
    </item>
    
  </channel>
</rss>
